import streamlit as st
import pandas as pd
import pickle
import numpy as np
import re
import os
import requests
import cv2
import base64
from PIL import Image, ImageEnhance, ImageDraw
from io import BytesIO
from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input
from tensorflow.keras.preprocessing import image
from sklearn.metrics.pairwise import cosine_similarity
from streamlit_image_coordinates import streamlit_image_coordinates

# -----------------------------------------------------------
# ğŸš‘ [í•„ìˆ˜ íŒ¨ì¹˜] Streamlit í˜¸í™˜ì„± í•´ê²° (í° í™”ë©´ ë°©ì§€)
# -----------------------------------------------------------
import streamlit.elements.image as st_image

def local_image_to_url(image, width=None, clamp=False, channels="RGB", output_format="auto", image_id=None):
    buffered = BytesIO()
    image.save(buffered, format="PNG")
    img_str = base64.b64encode(buffered.getvalue()).decode()
    return f"data:image/png;base64,{img_str}"

if not hasattr(st_image, 'image_to_url'):
    st_image.image_to_url = local_image_to_url
# -----------------------------------------------------------

# --- [1] ìœ í‹¸ë¦¬í‹° ë° ë¦¬ì†ŒìŠ¤ ë¡œë“œ ---
def get_direct_url(url):
    if not url or str(url) == 'nan' or 'drive.google.com' not in url: return url
    if 'file/d/' in url: file_id = url.split('file/d/')[1].split('/')[0]
    elif 'id=' in url: file_id = url.split('id=')[1].split('&')[0]
    else: return url
    return f'https://drive.google.com/uc?export=download&id={file_id}'

def load_csv_smart(target_name):
    files = os.listdir('.')
    for f in files:
        if f.lower() == target_name.lower():
            for enc in ['utf-8-sig', 'utf-8', 'cp949', 'euc-kr']:
                try: return pd.read_csv(f, encoding=enc)
                except: continue
    st.error(f"âŒ {target_name} íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    st.stop()

@st.cache_resource
def init_resources():
    model = ResNet50(weights='imagenet', include_top=False, pooling='avg')
    with open('material_features.pkl', 'rb') as f:
        feature_db = pickle.load(f)
    df_path = load_csv_smart('ì´ë¯¸ì§€ê²½ë¡œ.csv')
    df_info = load_csv_smart('í’ˆëª©ì •ë³´.csv')
    df_stock = load_csv_smart('í˜„ì¬ê³ .csv')
    
    df_stock['ì¬ê³ ìˆ˜ëŸ‰'] = pd.to_numeric(df_stock['ì¬ê³ ìˆ˜ëŸ‰'].astype(str).str.replace(',', ''), errors='coerce').fillna(0)
    df_stock['í’ˆë²ˆ_KEY'] = df_stock['í’ˆë²ˆ'].astype(str).str.strip().str.upper()
    agg_stock = df_stock.groupby('í’ˆë²ˆ_KEY')['ì¬ê³ ìˆ˜ëŸ‰'].sum().to_dict()
    stock_date = str(int(df_stock['ì •ì‚°ì¼ì'].max())) if 'ì •ì‚°ì¼ì' in df_stock.columns else "í™•ì¸ë¶ˆê°€"
    
    return model, feature_db, df_path, df_info, agg_stock, stock_date

model, feature_db, df_path, df_info, agg_stock, stock_date = init_resources()

def get_digits(text):
    return "".join(re.findall(r'\d+', str(text))) if text else ""

@st.cache_data
def get_master_map():
    mapping = {}
    for _, row in df_info.iterrows():
        f, l, n = str(row['ìƒí’ˆì½”ë“œ']).strip(), str(row['Lab No']).strip(), str(row['ìƒí’ˆëª…']).strip()
        val = {'formal': f, 'name': n}
        if get_digits(l): mapping[get_digits(l)] = val
        if get_digits(f): mapping[get_digits(f)] = val
    return mapping

master_map = get_master_map()

# --- [2] ì´ë¯¸ì§€ ì²˜ë¦¬ (íˆ¬ì˜ & ìŠ¤ë§ˆíŠ¸ í•„í„°) ---
def order_points(pts):
    rect = np.zeros((4, 2), dtype="float32")
    s = pts.sum(axis=1)
    rect[0] = pts[np.argmin(s)]
    rect[2] = pts[np.argmax(s)]
    diff = np.diff(pts, axis=1)
    rect[1] = pts[np.argmin(diff)]
    rect[3] = pts[np.argmax(diff)]
    return rect

def four_point_transform(image, pts):
    rect = order_points(pts)
    (tl, tr, br, bl) = rect
    widthA = np.sqrt(((br[0] - bl[0]) ** 2) + ((br[1] - bl[1]) ** 2))
    widthB = np.sqrt(((tr[0] - tl[0]) ** 2) + ((tr[1] - tl[1]) ** 2))
    maxWidth = max(int(widthA), int(widthB))
    heightA = np.sqrt(((tr[0] - br[0]) ** 2) + ((tr[1] - br[1]) ** 2))
    heightB = np.sqrt(((tl[0] - bl[0]) ** 2) + ((tl[1] - bl[1]) ** 2))
    maxHeight = max(int(heightA), int(heightB))
    dst = np.array([[0, 0], [maxWidth - 1, 0], [maxWidth - 1, maxHeight - 1], [0, maxHeight - 1]], dtype="float32")
    M = cv2.getPerspectiveTransform(rect, dst)
    warped = cv2.warpPerspective(image, M, (maxWidth, maxHeight))
    return warped

def apply_smart_filters(img, category, lighting, brightness, sharpness):
    # 1. ì¡°ëª… ë³´ì •
    if lighting == 'ë°±ì—´ë“± (ëˆ„ëŸ° ì¡°ëª…)':
        r, g, b = img.split()
        b = b.point(lambda i: i * 1.2)
        img = Image.merge('RGB', (r, g, b))
    elif lighting == 'í˜•ê´‘ë“± (í‘¸ë¥¸/ë…¹ìƒ‰ ì¡°ëª…)':
        r, g, b = img.split()
        r = r.point(lambda i: i * 1.1)
        img = Image.merge('RGB', (r, g, b))

    enhancer_con = ImageEnhance.Contrast(img)
    enhancer_shp = ImageEnhance.Sharpness(img)
    enhancer_bri = ImageEnhance.Brightness(img)
    enhancer_col = ImageEnhance.Color(img)

    # 2. ìì¬ë³„ ìë™ ë³´ì • (ì‚¬ìš©ìê°€ ê³ ë¥¸ ì¹´í…Œê³ ë¦¬ ê¸°ë°˜)
    if category == 'ë§ˆë£¨/ìš°ë“œ (Wood)':
        # ë‚˜ë­‡ê²° ê°•ì¡°: ì„ ëª…ë„ ëŒ€í­ ì¦ê°€, ëŒ€ë¹„ ì•½ê°„ ì¦ê°€
        img = enhancer_shp.enhance(2.0)
        img = enhancer_con.enhance(1.1)
    elif category == 'í•˜ì´ê·¸ë¡œì‹œ/ìœ ê´‘ (Glossy)':
        # ë¹›ë°˜ì‚¬ ì œê±°: ëŒ€ë¹„ ëŒ€í­ ì¦ê°€ (ë°˜ì‚¬ê´‘ ë‚ ë¦¼)
        img = enhancer_con.enhance(1.5)
        img = enhancer_shp.enhance(1.2)
    elif category == 'ë²½ì§€/íŒ¨ë¸Œë¦­ (Texture)':
        # ì§ˆê° ê°•ì¡°: ì ë‹¹í•œ ì„ ëª…ë„
        img = enhancer_shp.enhance(1.5)
        img = enhancer_bri.enhance(1.1)
    elif category == 'ì„ì¬/ì½˜í¬ë¦¬íŠ¸ (Stone)':
        # ìƒ‰ìƒ ì™œê³¡ ë°©ì§€: ì±„ë„ ê°ì†Œ, ì„ ëª…ë„ ì¦ê°€
        img = enhancer_col.enhance(0.8)
        img = enhancer_shp.enhance(1.5)
    
    # 3. ì‚¬ìš©ì ìˆ˜ë™ ë¯¸ì„¸ ì¡°ì •
    if brightness != 1.0: img = enhancer_bri.enhance(brightness)
    if sharpness != 1.0: img = enhancer_shp.enhance(sharpness)
        
    return img

def resize_for_display(img, max_width=800):
    if img.width > max_width:
        w_percent = (max_width / float(img.width))
        h_size = int((float(img.height) * float(w_percent)))
        return img.resize((max_width, h_size), Image.Resampling.LANCZOS)
    return img

# --- [3] ë©”ì¸ UI ---
st.set_page_config(layout="wide", page_title="ìŠ¤ë§ˆíŠ¸ ìì¬ ê²€ìƒ‰")
st.title("ğŸ­ ìŠ¤ë§ˆíŠ¸ ìì¬ íŒ¨í„´ ê²€ìƒ‰")
st.sidebar.info(f"ğŸ“… ì¬ê³  ê¸°ì¤€ì¼: {stock_date}")

# --- ì„¸ì…˜ ìƒíƒœ ê´€ë¦¬ ---
if 'points' not in st.session_state: st.session_state['points'] = []
if 'uploader_key' not in st.session_state: st.session_state['uploader_key'] = 0
if 'search_done' not in st.session_state: st.session_state['search_done'] = False

# --- ê°€ì´ë“œë¼ì¸ (Expander) ---
with st.expander("ğŸ“˜ [í•„ë…] ì‚¬ìš© ë°©ë²• ë° ì˜µì…˜ ê°€ì´ë“œ (í´ë¦­)", expanded=False):
    st.markdown("""
    **1. ì‚¬ì§„ ì´¬ì˜ ë° ì—…ë¡œë“œ**
    * ìµœëŒ€í•œ ì •ë©´ì—ì„œ ì°ìœ¼ë©´ ì¢‹ì§€ë§Œ, **ë¹„ìŠ¤ë“¬í•˜ê²Œ ì„œì„œ ì°ì–´ë„ ê´œì°®ìŠµë‹ˆë‹¤.** (4ì  ë³´ì • ê¸°ëŠ¥ì´ í´ì¤ë‹ˆë‹¤!)
    * **ê³ í™”ì§ˆ ì‚¬ì§„**ë„ ìë™ìœ¼ë¡œ ìµœì í™”ë˜ë¯€ë¡œ ê·¸ëƒ¥ ì—…ë¡œë“œí•˜ì„¸ìš”.

    **2. ìì¬ ì¢…ë¥˜ ì„ íƒ (ì¤‘ìš” â­)**
    * **ë§ˆë£¨/ìš°ë“œ:** ë‚˜ë­‡ê²°ì´ íë¦¿í•  ë•Œ ì„ íƒí•˜ì„¸ìš”. ì„ ëª…ë„ë¥¼ í™• ì˜¬ë ¤ì„œ ë¬´ëŠ¬ë¥¼ ì¡ì•„ëƒ…ë‹ˆë‹¤.
    * **í•˜ì´ê·¸ë¡œì‹œ:** ë¹› ë°˜ì‚¬ê°€ ì‹¬í•´ì„œ í•˜ì–—ê²Œ ëœ¬ ë¶€ë¶„ì´ ë§ì„ ë•Œ ì„ íƒí•˜ì„¸ìš”.
    * **ì„ì¬/ì½˜í¬ë¦¬íŠ¸:** ëŒ í‘œë©´ì˜ ê±°ì¹œ ì§ˆê°ì„ ì°¾ì„ ë•Œ ìœ ë¦¬í•©ë‹ˆë‹¤.

    **3. ì˜ì—­ ì§€ì • (4ì  ì½•ì½•)**
    * ë§ˆìš°ìŠ¤ë¡œ ìì¬ì˜ **ëª¨ì„œë¦¬ 4êµ°ë°ë¥¼ í´ë¦­**í•˜ì„¸ìš”.
    * 4ë²ˆì§¸ ì ì„ ì°ëŠ” ìˆœê°„, ì°Œê·¸ëŸ¬ì§„ ì‚¬ì§„ì´ **ë„¤ëª¨ ë°˜ë“¯í•˜ê²Œ** í´ì§‘ë‹ˆë‹¤.
    
    **4. ê²€ìƒ‰ ëª¨ë“œ**
    * **íŒ¨í„´ ì¤‘ì‹¬(í‘ë°±):** "ìƒ‰ê¹”ì€ ë‹¬ë¼ë„ ë˜ë‹ˆ ë¬´ëŠ¬ê°€ ë˜‘ê°™ì€ ê±¸ ì°¾ì•„ì¤˜!" (ì¶”ì²œ ğŸ‘)
    * **ì»¬ëŸ¬+íŒ¨í„´:** "ìƒ‰ê¹”ë„ ë¹„ìŠ·í•´ì•¼ í•´!" (ìš°ë“œ í†¤ êµ¬ë¶„í•  ë•Œ)
    """)

# --- ì—…ë¡œë” ë° ì´ˆê¸°í™” ---
uploaded = st.file_uploader("ìì¬ ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”", type=['jpg', 'png', 'tif', 'jpeg'], key=f"up_{st.session_state['uploader_key']}")

# ì´ë¯¸ì§€ ë¦¬ì…‹ ë²„íŠ¼
if st.sidebar.button("ğŸ”„ ì²˜ìŒë¶€í„° ë‹¤ì‹œ í•˜ê¸° (Reset)"):
    st.session_state['points'] = []
    st.session_state['search_done'] = False
    st.session_state['search_results'] = None
    st.session_state['uploader_key'] += 1
    st.rerun()

if uploaded:
    # ğŸ§¹ [ìë™ ë¦¬ì…‹] ìƒˆë¡œìš´ íŒŒì¼ì´ ë“¤ì–´ì˜¤ë©´ ê¸°ì¡´ ê²°ê³¼/ì¢Œí‘œ ì‹¹ ì§€ìš°ê¸°
    if 'current_img_name' not in st.session_state or st.session_state['current_img_name'] != uploaded.name:
        st.session_state['points'] = []
        st.session_state['search_done'] = False
        st.session_state['search_results'] = None
        st.session_state['current_img_name'] = uploaded.name
        
        # â³ [ë¡œë”© í‘œì‹œ] ëŒ€ìš©ëŸ‰ ì´ë¯¸ì§€ ì²˜ë¦¬ ì¤‘ ì‚¬ìš©ì ì•ˆì‹¬ì‹œí‚¤ê¸°
        with st.spinner('ğŸ“¸ ê³ í™”ì§ˆ ì´ë¯¸ì§€ë¥¼ ë¶„ì„ìš©ìœ¼ë¡œ ìµœì í™”í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤... ì ì‹œë§Œìš”!'):
            try:
                raw = Image.open(uploaded).convert('RGB')
                st.session_state['proc_img'] = resize_for_display(raw, max_width=800)
            except:
                st.error("ì´ë¯¸ì§€ë¥¼ ì²˜ë¦¬í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                st.stop()

    working_img = st.session_state['proc_img']

    # --- ì˜µì…˜ ì„¤ì • UI ---
    st.markdown("### 1ï¸âƒ£ í™˜ê²½ ì„¤ì •")
    
    col_opt1, col_opt2 = st.columns(2)
    with col_opt1:
        material_type = st.selectbox(
            "ğŸ§± ìì¬ ì¢…ë¥˜ (ìë™ í•„í„°)", 
            ['ì¼ë°˜ (ê¸°ë³¸)', 'ë§ˆë£¨/ìš°ë“œ (Wood)', 'í•˜ì´ê·¸ë¡œì‹œ/ìœ ê´‘ (Glossy)', 'ë²½ì§€/íŒ¨ë¸Œë¦­ (Texture)', 'ì„ì¬/ì½˜í¬ë¦¬íŠ¸ (Stone)'],
            help="ìì¬ íŠ¹ì„±ì— ë§ì¶° AIê°€ ë” ì˜ ë³¼ ìˆ˜ ìˆë„ë¡ ì´ë¯¸ì§€ë¥¼ ìë™ ë³´ì •í•©ë‹ˆë‹¤."
        )
    with col_opt2:
        search_mode = st.radio(
            "ğŸ” ê²€ìƒ‰ ê¸°ì¤€", 
            ["ğŸ¨ ì»¬ëŸ¬ + íŒ¨í„´ ì¢…í•©", "ğŸ¦“ íŒ¨í„´/ì§ˆê° ì¤‘ì‹¬ (ìƒ‰ìƒ ë¬´ì‹œ)"], 
            horizontal=True,
            help="ì¡°ëª… ë•Œë¬¸ì— ìƒ‰ì´ ì´ìƒí•˜ê²Œ ì°í˜”ë‹¤ë©´ 'íŒ¨í„´ ì¤‘ì‹¬'ì„ ì„ íƒí•˜ì„¸ìš”. í‘ë°±ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ë¬´ëŠ¬ë§Œ ë¹„êµí•©ë‹ˆë‹¤."
        )

    with st.expander("âš™ï¸ ê³ ê¸‰ ì„¤ì • (ì¡°ëª…, íšŒì „, ë°ê¸°)", expanded=False):
        c1, c2, c3 = st.columns(3)
        with c1:
            lighting = st.selectbox("ì¡°ëª… ìƒ‰ìƒ", ['ì¼ë°˜/ìì—°ê´‘', 'ë°±ì—´ë“± (ëˆ„ëŸ° ì¡°ëª…)', 'í˜•ê´‘ë“± (í‘¸ë¥¸/ë…¹ìƒ‰ ì¡°ëª…)'], help="í˜„ì¥ ì¡°ëª…ì´ ë„ˆë¬´ ë…¸ë—ê±°ë‚˜ í‘¸ë¥´ë‹¤ë©´ ì„ íƒí•˜ì„¸ìš”.")
        with c2:
            if st.button("â†©ï¸ ì‚¬ì§„ 90ë„ íšŒì „"):
                st.session_state['proc_img'] = working_img.rotate(90, expand=True)
                st.session_state['points'] = [] # íšŒì „í•˜ë©´ ì¢Œí‘œ ì´ˆê¸°í™”
                st.rerun()
        with c3:
            brightness = st.slider("ë°ê¸° ì¡°ì ˆ", 0.5, 2.0, 1.0, 0.1, help="ì‚¬ì§„ì´ ë„ˆë¬´ ì–´ë‘ìš°ë©´ ë°ê²Œ, ë„ˆë¬´ ë°ìœ¼ë©´ ì–´ë‘¡ê²Œ ì¡°ì ˆí•˜ì„¸ìš”.")
            sharpness = st.slider("ì„ ëª…ë„ ì¡°ì ˆ", 0.0, 3.0, 1.5, 0.1, help="ë¬´ëŠ¬ê°€ íë¦¿í•˜ë©´ ì„ ëª…ë„ë¥¼ ë†’ì´ì„¸ìš”.")

    # --- ì¢Œí‘œ ì°ê¸° ---
    st.markdown("### 2ï¸âƒ£ ì˜ì—­ ì§€ì • (4ì  í´ë¦­)")
    st.info(f"ğŸ‘‡ ì´ë¯¸ì§€ì—ì„œ ë¶„ì„í•  ìì¬ì˜ **ëª¨ì„œë¦¬ 4ê³³ì„ í´ë¦­**í•´ì£¼ì„¸ìš”. ({len(st.session_state['points'])}/4 ì™„ë£Œ)")
    
    draw_img = working_img.copy()
    draw = ImageDraw.Draw(draw_img)
    
    # ì  ê·¸ë¦¬ê¸°
    for i, p in enumerate(st.session_state['points']):
        draw.ellipse((p[0]-8, p[1]-8, p[0]+8, p[1]+8), fill='red', outline='white', width=2)
        draw.text((p[0]+10, p[1]-10), str(i+1), fill='red')

    # 4ì  ì™„ì„± ì‹œ ì„  ê·¸ë¦¬ê¸°
    if len(st.session_state['points']) == 4:
        pts = np.array(st.session_state['points'])
        rect = order_points(pts)
        draw.polygon([tuple(p) for p in rect], outline='#00FF00', width=4)

    # ì¸í„°ë™í‹°ë¸Œ ì´ë¯¸ì§€
    value = streamlit_image_coordinates(draw_img, key="click_pad")

    if value is not None:
        new_point = (value['x'], value['y'])
        if len(st.session_state['points']) < 4:
            if not st.session_state['points'] or st.session_state['points'][-1] != new_point:
                st.session_state['points'].append(new_point)
                st.rerun()

    if len(st.session_state['points']) > 0 and len(st.session_state['points']) < 4:
        if st.button("âŒ ì  ì·¨ì†Œí•˜ê³  ë‹¤ì‹œ ì°ê¸°"):
            st.session_state['points'] = []
            st.rerun()

    # --- ë¶„ì„ ë° ê²°ê³¼ ---
    if len(st.session_state['points']) == 4:
        st.markdown("### 3ï¸âƒ£ ë¶„ì„ ê²°ê³¼")
        
        pts = np.array(st.session_state['points'], dtype="float32")
        cv_img = np.array(working_img)
        warped = four_point_transform(cv_img, pts)
        
        final_img = Image.fromarray(warped)
        
        # [ìŠ¤ë§ˆíŠ¸ í•„í„° ì ìš©]
        final_img = apply_smart_filters(final_img, material_type, lighting, brightness, sharpness)
        
        # [íŒ¨í„´ ëª¨ë“œì¼ ê²½ìš° í‘ë°± ë³€í™˜]
        if search_mode == "ğŸ¦“ íŒ¨í„´/ì§ˆê° ì¤‘ì‹¬ (ìƒ‰ìƒ ë¬´ì‹œ)":
            final_img = final_img.convert("L").convert("RGB")

        col_prev1, col_prev2 = st.columns(2)
        with col_prev1: 
            st.image(final_img, caption="AIê°€ ë¶„ì„í•  ìµœì¢… ì´ë¯¸ì§€", width=300)
        with col_prev2:
            st.write("ğŸ‘‰ ì´ë¯¸ì§€ê°€ ì˜ í´ì¡Œë‚˜ìš”?")
            if st.button("ğŸ” ì´ëŒ€ë¡œ ê²€ìƒ‰ ì‹œì‘", type="primary"):
                with st.spinner('AIê°€ ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ë’¤ì§€ëŠ” ì¤‘ì…ë‹ˆë‹¤...'):
                    x = image.img_to_array(final_img.resize((224, 224)))
                    x = np.expand_dims(x, axis=0)
                    query_vec = model.predict(preprocess_input(x), verbose=0).flatten().reshape(1, -1)
                    
                    db_names, db_vecs = list(feature_db.keys()), np.array(list(feature_db.values()))
                    sims = cosine_similarity(query_vec, db_vecs).flatten()
                    
                    results = []
                    for i in range(len(db_names)):
                        fname = db_names[i]
                        info = master_map.get(get_digits(fname), {'formal': fname, 'name': 'ì •ë³´ ì—†ìŒ'})
                        formal = info['formal']
                        qty = agg_stock.get(formal.strip().upper(), 0)
                        
                        url_row = df_path[df_path['ì¶”ì¶œëœ_í’ˆë²ˆ'].apply(get_digits) == get_digits(fname)]
                        if url_row.empty: url_row = df_path[df_path['íŒŒì¼ëª…'] == fname]
                        url = url_row['ì¹´ì¹´ì˜¤í†¡_ì „ì†¡ìš©_URL'].values[0] if not url_row.empty else None
                        
                        results.append({'formal': formal, 'name': info['name'], 'score': sims[i], 'stock': qty, 'url': url})
                    
                    results = sorted(results, key=lambda x: x['score'], reverse=True)
                    st.session_state['search_results'] = results
                    st.session_state['search_done'] = True
                    st.rerun() # ê²°ê³¼ì°½ ë°”ë¡œ ë„ìš°ê¸° ìœ„í•´ ë¦¬ëŸ°

    # ê²°ê³¼ í‘œì‹œ
    if st.session_state.get('search_done'):
        st.markdown("---")
        results = st.session_state['search_results']
        def display_card(item, idx):
            st.markdown(f"**{idx}. {item['formal']}**")
            st.write(f"{item['name']}")
            st.caption(f"ìœ ì‚¬ë„: {item['score']:.1%}")
            if item['url']:
                st.markdown(f"ğŸ”— [**ê³ í™”ì§ˆ ì›ë³¸**]({item['url']})")
                with st.expander("ğŸ–¼ï¸ í¼ì¹˜ê¸°", expanded=False):
                    try:
                        r = requests.get(get_direct_url(item['url']), timeout=5)
                        st.image(Image.open(BytesIO(r.content)), use_container_width=True)
                    except: st.write("ë¡œë”© ì‹¤íŒ¨")
            else: st.write("ì´ë¯¸ì§€ ì—†ìŒ")
            if item['stock'] >= 100: st.success(f"{item['stock']:,}m")
            else: st.write(f"{item['stock']:,}m")

        t1, t2 = st.tabs(["ğŸ“Š ì „ì²´ ê²°ê³¼", "âœ… ì¬ê³  ë³´ìœ  (100mâ†‘)"])
        with t1:
            cols = st.columns(5)
            for i, r in enumerate(results[:10]):
                with cols[i%5]: display_card(r, i+1)
        with t2:
            hits = [r for r in results if r['stock'] >= 100]
            if hits:
                cols = st.columns(5)
                for i, r in enumerate(hits[:10]):
                    with cols[i%5]: display_card(r, i+1)
            else: st.warning("ì¬ê³  ë³´ìœ  ìì¬ ì—†ìŒ")
