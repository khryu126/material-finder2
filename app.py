import streamlit as st
import pandas as pd
import pickle
import numpy as np
import re
import os
import requests
import cv2
import base64
from PIL import Image, ImageEnhance, ImageDraw, ImageFilter, ImageOps
from io import BytesIO
from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input
from tensorflow.keras.preprocessing import image
from sklearn.metrics.pairwise import cosine_similarity
from streamlit_image_coordinates import streamlit_image_coordinates

# -----------------------------------------------------------
# ğŸš‘ [ì‹œìŠ¤í…œ íŒ¨ì¹˜] Streamlit ì´ë¯¸ì§€ ë Œë”ë§ í˜¸í™˜ì„± í•´ê²°
# -----------------------------------------------------------
import streamlit.elements.image as st_image

def local_image_to_url(image, width=None, clamp=False, channels="RGB", output_format="auto", image_id=None):
    buffered = BytesIO()
    image.save(buffered, format="PNG")
    img_str = base64.b64encode(buffered.getvalue()).decode()
    return f"data:image/png;base64,{img_str}"

if not hasattr(st_image, 'image_to_url'):
    st_image.image_to_url = local_image_to_url

# -----------------------------------------------------------
# --- [1] ìœ í‹¸ë¦¬í‹° ë° ë°ì´í„° ë§¤í•‘ ë¡œì§ ---
# -----------------------------------------------------------

def get_direct_url(url):
    """êµ¬ê¸€ ë“œë¼ì´ë¸Œ URL ë³€í™˜ (ì•ˆì •ì  ë‹¤ìš´ë¡œë“œ ë§í¬)"""
    if not url or str(url) == 'nan' or 'drive.google.com' not in url: 
        return url
    file_id = ""
    if 'file/d/' in url: file_id = url.split('file/d/')[1].split('/')[0]
    elif 'id=' in url: file_id = url.split('id=')[1].split('&')[0]
    return f'https://drive.google.com/uc?export=download&id={file_id}' if file_id else url

def is_formal_code(code):
    """ì •ì‹ í’ˆë²ˆ(14-54130-119 ë“±) í˜•ì‹ ê²€ì‚¬"""
    if not code or pd.isna(code): return False
    pattern = r'^\d+-\d+-\d+$' # ìˆ«ì-ìˆ«ì-ìˆ«ì í˜•íƒœ
    return bool(re.match(pattern, str(code).strip()))

def extract_digits(text):
    """4ìë¦¬ ì´ìƒ í•µì‹¬ ìˆ«ì ì¶”ì¶œ (ë§¤ì¹­ í‚¤)"""
    if pd.isna(text) or str(text).strip() == '-': return ""
    nums = re.findall(r'\d{4,}', str(text))
    return nums[0] if nums else ""

@st.cache_resource
def init_resources():
    model = ResNet50(weights='imagenet', include_top=False, pooling='avg')
    
    # íŠ¹ì§•ê°’ DB ë¡œë“œ
    if os.path.exists('material_features.pkl'):
        with open('material_features.pkl', 'rb') as f:
            feature_db = pickle.load(f)
    else:
        st.error("âŒ material_features.pkl íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        st.stop()

    def load_csv(name):
        for enc in ['utf-8-sig', 'cp949']:
            try: return pd.read_csv(name, encoding=enc)
            except: continue
        return None

    df_path = load_csv('ì´ë¯¸ì§€ê²½ë¡œ.csv')
    df_info = load_csv('í’ˆëª©ì •ë³´.csv')
    df_stock = load_csv('í˜„ì¬ê³ .csv')
    
    # ì¬ê³  ë°ì´í„° ì „ì²˜ë¦¬
    df_stock['ì¬ê³ ìˆ˜ëŸ‰'] = pd.to_numeric(df_stock['ì¬ê³ ìˆ˜ëŸ‰'].astype(str).str.replace(',', ''), errors='coerce').fillna(0)
    df_stock['í’ˆë²ˆ_KEY'] = df_stock['í’ˆë²ˆ'].apply(extract_digits)
    agg_stock = df_stock.groupby('í’ˆë²ˆ_KEY')['ì¬ê³ ìˆ˜ëŸ‰'].sum().to_dict()
    stock_date = str(int(df_stock['ì •ì‚°ì¼ì'].max())) if 'ì •ì‚°ì¼ì' in df_stock.columns else "í™•ì¸ë¶ˆê°€"
    
    return model, feature_db, df_path, df_info, agg_stock, stock_date

model, feature_db, df_path, df_info, agg_stock, stock_date = init_resources()

@st.cache_data
def get_master_map():
    """í’ˆë²ˆ ìš°ì„ ìˆœìœ„ ì ìš© ë§¤í•‘ (ì •ì‹ ê·œê²© ìš°ì„ )"""
    mapping = {}
    for _, row in df_info.iterrows():
        f = str(row.get('ìƒí’ˆì½”ë“œ', '')).strip()
        l = str(row.get('Lab No', '')).strip()
        n = str(row.get('ìƒí’ˆëª…', '')).strip()
        
        info = {'formal': f if f else l, 'name': n, 'lab_no': l}
        
        keys = {extract_digits(f), extract_digits(l), f, l}
        for k in keys:
            if not k: continue
            if k not in mapping:
                mapping[k] = info
            else:
                # ğŸš€ ì •ì‹ ê·œê²©ì´ ë‚˜íƒ€ë‚˜ë©´ ì„ì‹œ ë²ˆí˜¸ ì •ë³´ë¥¼ ë®ì–´ì”Œì›€
                if is_formal_code(info['formal']) and not is_formal_code(mapping[k]['formal']):
                    mapping[k] = info
    return mapping

master_map = get_master_map()

# -----------------------------------------------------------
# --- [2] ì´ë¯¸ì§€ ë¶„ì„ ë° ë³€í™˜ ë¡œì§ ---
# -----------------------------------------------------------

def prepare_image_for_ai(img, mode):
    """ì´ë¯¸ì§€ ì „ì²˜ë¦¬: ëŒ€ë¹„ ì •ê·œí™”ë¡œ ë°ê¸° ì°¨ì´ ê·¹ë³µ"""
    img = img.resize((224, 224))
    if mode == "ğŸ¦“ íŒ¨í„´ ì¤‘ì‹¬(í‘ë°±)":
        img = img.convert("L").convert("RGB")
    elif mode == "ğŸ¨ ì»¬ëŸ¬ ì¤‘ì‹¬(ë¸”ëŸ¬)":
        img = img.filter(ImageFilter.GaussianBlur(radius=15))
    else:
        # ë°ê¸°/ëŒ€ë¹„ ì •ê·œí™”ë¥¼ í†µí•´ ìƒ‰ìƒ í†¤ ì˜¤ì°¨ ê°ì†Œ
        img = ImageOps.autocontrast(img, cutoff=1)
    return img

def order_points(pts):
    rect = np.zeros((4, 2), dtype="float32")
    s = pts.sum(axis=1)
    rect[0], rect[2] = pts[np.argmin(s)], pts[np.argmax(s)]
    diff = np.diff(pts, axis=1)
    rect[1], rect[3] = pts[np.argmin(diff)], pts[np.argmax(diff)]
    return rect

def four_point_transform(image, pts):
    rect = order_points(pts)
    (tl, tr, br, bl) = rect
    width = max(int(np.sqrt(((br[0]-bl[0])**2) + ((br[1]-bl[1])**2))), int(np.sqrt(((tr[0]-tl[0])**2) + ((tr[1]-tl[1])**2))))
    height = max(int(np.sqrt(((tr[0]-br[0])**2) + ((tr[1]-br[1])**2))), int(np.sqrt(((tl[0]-bl[0])**2) + ((tl[1]-bl[1])**2))))
    dst = np.array([[0, 0], [width - 1, 0], [width - 1, height - 1], [0, height - 1]], dtype="float32")
    M = cv2.getPerspectiveTransform(rect, dst)
    return cv2.warpPerspective(image, M, (width, height))

# -----------------------------------------------------------
# --- [3] ë©”ì¸ UI (ì˜ì—­ ì§€ì • ë³µêµ¬) ---
# -----------------------------------------------------------

st.set_page_config(layout="wide", page_title="ìŠ¤ë§ˆíŠ¸ ìì¬ ê²€ìƒ‰")
st.title("ğŸ­ ìŠ¤ë§ˆíŠ¸ ìì¬ íŒ¨í„´ ê²€ìƒ‰")

# ì‚¬ì´ë“œë°” ì •ë³´
st.sidebar.info(f"ğŸ“… ì¬ê³  ê¸°ì¤€ì¼: {stock_date}")
if st.sidebar.button("ğŸ”„ ì²˜ìŒë¶€í„° ë‹¤ì‹œ í•˜ê¸° (Reset)"):
    for key in ['points', 'search_done', 'search_results', 'raw_img']:
        if key in st.session_state: del st.session_state[key]
    st.rerun()

tab1, tab2 = st.tabs(["ğŸ“‚ íŒŒì¼ ì—…ë¡œë“œ", "ğŸ“¸ ì¹´ë©”ë¼ ì´¬ì˜"])
input_file = None
with tab1:
    uploaded = st.file_uploader("ì´ë¯¸ì§€ íŒŒì¼", type=['jpg', 'png', 'jpeg'], key="up")
    if uploaded: input_file = uploaded
with tab2:
    camera_shot = st.camera_input("ì¹´ë©”ë¼ ì´¬ì˜")
    if camera_shot: input_file = camera_shot

if input_file:
    if 'raw_img' not in st.session_state:
        st.session_state['raw_img'] = Image.open(input_file).convert('RGB')
        st.session_state['points'] = []

    raw = st.session_state['raw_img']
    
    st.markdown("### 1ï¸âƒ£ í™˜ê²½ ë° ê²€ìƒ‰ ì„¤ì •")
    c1, c2 = st.columns(2)
    with c1: source_type = st.radio("ğŸ“‚ ì›ë³¸ ì¢…ë¥˜", ['ğŸ“¸ í˜„ì¥ ì´¬ì˜', 'ğŸ’» ë””ì§€í„¸ ìŠ¤ìº”'], horizontal=True)
    with c2: search_mode = st.radio("ğŸ” ê²€ìƒ‰ ê¸°ì¤€", ["ğŸ¨ ì»¬ëŸ¬+íŒ¨í„´", "ğŸ¦“ íŒ¨í„´ ì¤‘ì‹¬(í‘ë°±)", "ğŸ¨ ì»¬ëŸ¬ ì¤‘ì‹¬(ë¸”ëŸ¬)"], horizontal=True)

    st.markdown("### 2ï¸âƒ£ ì˜ì—­ ì§€ì •")
    zoom = st.slider("ğŸ” ì´ë¯¸ì§€ í™•ëŒ€/ì¶•ì†Œ", 400, 1200, 700)
    display_img = raw.copy()
    display_img.thumbnail((zoom, zoom))
    
    # ğŸš€ [ë³µêµ¬] ì  ì§€ìš°ê¸° ë° ì•ˆë‚´ ì„¹ì…˜
    col_sel1, col_sel2 = st.columns([3, 1])
    with col_sel1:
        st.info(f"ğŸ‘‡ **ëª¨ì„œë¦¬ 4ê³³ì„ í´ë¦­**í•˜ì„¸ìš”. ({len(st.session_state['points'])}/4)")
    with col_sel2:
        if st.button("âŒ ì  ì§€ìš°ê¸° (Undo)", use_container_width=True):
            st.session_state['points'] = []
            st.rerun()
    
    # í¬ì¸íŠ¸ ìº”ë²„ìŠ¤
    draw = ImageDraw.Draw(display_img)
    for i, p in enumerate(st.session_state['points']):
        draw.ellipse((p[0]-6, p[1]-6, p[0]+6, p[1]+6), fill='red', outline='white', width=2)
        draw.text((p[0]+10, p[1]-10), str(i+1), fill='red')
    
    val = streamlit_image_coordinates(display_img, key="roi_click")
    if val:
        new_p = (val['x'], val['y'])
        if len(st.session_state['points']) < 4:
            if not st.session_state['points'] or st.session_state['points'][-1] != new_p:
                st.session_state['points'].append(new_p)
                st.rerun()

    # 4ê°œ ì ì´ ëª¨ë‘ ì°íˆë©´ ë¶„ì„ ì¤€ë¹„
    if len(st.session_state['points']) == 4:
        st.markdown("---")
        ratio = raw.width / display_img.width
        pts = np.array(st.session_state['points'], dtype="float32") * ratio
        warped = four_point_transform(np.array(raw), pts)
        final_crop = Image.fromarray(warped)
        
        col_crop1, col_crop2 = st.columns([1, 2])
        with col_crop1:
            st.image(final_crop, caption="ì˜ë¼ë‚¸ ìì¬ ì´ë¯¸ì§€", width=300)
        with col_crop2:
            st.write("âœ… ì˜ì—­ ì§€ì • ì™„ë£Œ. ê²€ìƒ‰ì„ ì‹œì‘í•˜ì„¸ìš”.")
            if st.button("ğŸ” ìœ ì‚¬ ìì¬ ê²€ìƒ‰ ì‹œì‘", type="primary", use_container_width=True):
                with st.spinner('ìœ ì‚¬í•œ ìì¬ë¥¼ ì°¾ëŠ” ì¤‘...'):
                    proc_img = prepare_image_for_ai(final_crop, search_mode)
                    x = image.img_to_array(proc_img)
                    x = np.expand_dims(x, axis=0)
                    query_vec = model.predict(preprocess_input(x), verbose=0).flatten().reshape(1, -1)
                    
                    db_names, db_vecs = list(feature_db.keys()), np.array(list(feature_db.values()))
                    sims = cosine_similarity(query_vec, db_vecs).flatten()
                    
                    raw_res = []
                    for i in range(len(db_names)):
                        digits = extract_digits(db_names[i])
                        info = master_map.get(digits, {'formal': db_names[i], 'name': 'ì •ë³´ì—†ìŒ', 'lab_no': '-'})
                        
                        url_match = df_path[df_path['ì¶”ì¶œëœ_í’ˆë²ˆ'].apply(extract_digits) == digits]
                        url = url_match.iloc[0]['ì¹´ì¹´ì˜¤í†¡_ì „ì†¡ìš©_URL'] if not url_match.empty else None
                        stock = agg_stock.get(extract_digits(info['formal']), 0)
                        
                        raw_res.append({'info': info, 'score': sims[i], 'stock': stock, 'url': url})
                    
                    raw_res.sort(key=lambda x: x['score'], reverse=True)
                    unique_res, seen = [], set()
                    for r in raw_res:
                        if r['info']['formal'] not in seen:
                            unique_res.append(r); seen.add(r['info']['formal'])
                    
                    st.session_state['search_results'] = unique_res[:20]
                    st.session_state['search_done'] = True
                    st.rerun()

# -----------------------------------------------------------
# --- [4] ê²°ê³¼ ì¶œë ¥ ---
# -----------------------------------------------------------

if st.session_state.get('search_done'):
    st.markdown("### ğŸ† ê²€ìƒ‰ ê²°ê³¼ (ìƒìœ„ 20ê°œ)")
    results = st.session_state['search_results']
    
    cols = st.columns(5)
    for i, item in enumerate(results):
        with cols[i % 5]:
            info = item['info']
            st.markdown(f"**{i+1}. {info['formal']}**")
            if info['lab_no'] != '-' and info['lab_no'] != info['formal']:
                st.caption(f"(Lab: {info['lab_no']})")
            st.write(f"{info['name']}")
            st.caption(f"ìœ ì‚¬ë„: {item['score']:.1%}")
            
            if item['url']:
                with st.expander("ğŸ–¼ï¸ ì´ë¯¸ì§€ í™•ì¸"):
                    try:
                        r = requests.get(get_direct_url(item['url']), timeout=5)
                        st.image(Image.open(BytesIO(r.content)), use_container_width=True)
                    except: st.write("ë¡œë”© ì‹¤íŒ¨")
                st.markdown(f"ğŸ”— [ì›ë³¸ ë§í¬]({item['url']})")
            
            if item['stock'] >= 100: st.success(f"{item['stock']:,}m")
            else: st.info(f"{item['stock']:,}m")
