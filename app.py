import streamlit as st
import pandas as pd
import pickle
import numpy as np
import re
import os
import requests
import cv2
import base64
from PIL import Image, ImageEnhance
from io import BytesIO
from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input
from tensorflow.keras.preprocessing import image
from sklearn.metrics.pairwise import cosine_similarity

# -----------------------------------------------------------
# ğŸš‘ [ê¸´ê¸‰ íŒ¨ì¹˜] Streamlit ìµœì‹  ë²„ì „ í˜¸í™˜ì„± í•´ê²° ì½”ë“œ (í•„ìˆ˜)
# ì‚¬ë¼ì§„ image_to_url í•¨ìˆ˜ë¥¼ ê°•ì œë¡œ ë§Œë“¤ì–´ì„œ ì£¼ì…í•©ë‹ˆë‹¤.
# -----------------------------------------------------------
import streamlit.elements.image as st_image

def local_image_to_url(image, width=None, clamp=False, channels="RGB", output_format="auto", image_id=None):
    """PIL ì´ë¯¸ì§€ë¥¼ HTMLì—ì„œ ë³¼ ìˆ˜ ìˆëŠ” Base64 ì£¼ì†Œë¡œ ë³€í™˜"""
    buffered = BytesIO()
    try:
        fmt = image.format if image.format else "PNG"
    except:
        fmt = "PNG"
    image.save(buffered, format=fmt)
    img_str = base64.b64encode(buffered.getvalue()).decode()
    return f"data:image/{fmt.lower()};base64,{img_str}"

# ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì°¾ì„ ìˆ˜ ìˆë„ë¡ í•¨ìˆ˜ ì£¼ì… (Monkey Patching)
if not hasattr(st_image, 'image_to_url'):
    st_image.image_to_url = local_image_to_url
# -----------------------------------------------------------

from streamlit_drawable_canvas import st_canvas

# --- [1] ê¸°ë³¸ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ---
def get_direct_url(url):
    if not url or str(url) == 'nan' or 'drive.google.com' not in url: return url
    if 'file/d/' in url: file_id = url.split('file/d/')[1].split('/')[0]
    elif 'id=' in url: file_id = url.split('id=')[1].split('&')[0]
    else: return url
    return f'https://drive.google.com/uc?export=download&id={file_id}'

def load_csv_smart(target_name):
    files = os.listdir('.')
    for f in files:
        if f.lower() == target_name.lower():
            for enc in ['utf-8-sig', 'utf-8', 'cp949', 'euc-kr']:
                try: return pd.read_csv(f, encoding=enc)
                except: continue
    st.error(f"âŒ {target_name} íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    st.stop()

@st.cache_resource
def init_resources():
    model = ResNet50(weights='imagenet', include_top=False, pooling='avg')
    with open('material_features.pkl', 'rb') as f:
        feature_db = pickle.load(f)
    df_path = load_csv_smart('ì´ë¯¸ì§€ê²½ë¡œ.csv')
    df_info = load_csv_smart('í’ˆëª©ì •ë³´.csv')
    df_stock = load_csv_smart('í˜„ì¬ê³ .csv')
    
    df_stock['ì¬ê³ ìˆ˜ëŸ‰'] = pd.to_numeric(df_stock['ì¬ê³ ìˆ˜ëŸ‰'].astype(str).str.replace(',', ''), errors='coerce').fillna(0)
    df_stock['í’ˆë²ˆ_KEY'] = df_stock['í’ˆë²ˆ'].astype(str).str.strip().str.upper()
    agg_stock = df_stock.groupby('í’ˆë²ˆ_KEY')['ì¬ê³ ìˆ˜ëŸ‰'].sum().to_dict()
    stock_date = str(int(df_stock['ì •ì‚°ì¼ì'].max())) if 'ì •ì‚°ì¼ì' in df_stock.columns else "í™•ì¸ë¶ˆê°€"
    
    return model, feature_db, df_path, df_info, agg_stock, stock_date

model, feature_db, df_path, df_info, agg_stock, stock_date = init_resources()

def get_digits(text):
    return "".join(re.findall(r'\d+', str(text))) if text else ""

@st.cache_data
def get_master_map():
    mapping = {}
    for _, row in df_info.iterrows():
        f, l, n = str(row['ìƒí’ˆì½”ë“œ']).strip(), str(row['Lab No']).strip(), str(row['ìƒí’ˆëª…']).strip()
        val = {'formal': f, 'name': n}
        if get_digits(l): mapping[get_digits(l)] = val
        if get_digits(f): mapping[get_digits(f)] = val
    return mapping

master_map = get_master_map()

# --- [2] íˆ¬ì˜ ë³€í™˜ (Perspective Transform) ë¡œì§ ---
def order_points(pts):
    rect = np.zeros((4, 2), dtype="float32")
    s = pts.sum(axis=1)
    rect[0] = pts[np.argmin(s)] # ì¢Œìƒ
    rect[2] = pts[np.argmax(s)] # ìš°í•˜
    diff = np.diff(pts, axis=1)
    rect[1] = pts[np.argmin(diff)] # ìš°ìƒ
    rect[3] = pts[np.argmax(diff)] # ì¢Œí•˜
    return rect

def four_point_transform(image, pts):
    rect = order_points(pts)
    (tl, tr, br, bl) = rect
    widthA = np.sqrt(((br[0] - bl[0]) ** 2) + ((br[1] - bl[1]) ** 2))
    widthB = np.sqrt(((tr[0] - tl[0]) ** 2) + ((tr[1] - tl[1]) ** 2))
    maxWidth = max(int(widthA), int(widthB))
    heightA = np.sqrt(((tr[0] - br[0]) ** 2) + ((tr[1] - br[1]) ** 2))
    heightB = np.sqrt(((tl[0] - bl[0]) ** 2) + ((tl[1] - bl[1]) ** 2))
    maxHeight = max(int(heightA), int(heightB))
    dst = np.array([[0, 0], [maxWidth - 1, 0], [maxWidth - 1, maxHeight - 1], [0, maxHeight - 1]], dtype="float32")
    M = cv2.getPerspectiveTransform(rect, dst)
    warped = cv2.warpPerspective(image, M, (maxWidth, maxHeight))
    return warped

# --- [3] í†µí•© ì´ë¯¸ì§€ ë³´ì • í•¨ìˆ˜ (ëª¨ë“  ì˜µì…˜ í¬í•¨) ---
def apply_filters(img, source_type, lighting, surface, flooring_mode, brightness, sharpness):
    if source_type == 'ì´ë¯¸ì§€ íŒŒì¼ (ìŠ¤ìº”/ë””ì§€í„¸)':
        return img # ì›ë³¸ì€ ë³´ì • íŒ¨ìŠ¤

    # 1. ì¡°ëª… ë³´ì •
    if lighting == 'ë°±ì—´ë“± (ëˆ„ëŸ° ì¡°ëª…)':
        r, g, b = img.split()
        b = b.point(lambda i: i * 1.2)
        img = Image.merge('RGB', (r, g, b))
    elif lighting == 'í˜•ê´‘ë“± (í‘¸ë¥¸/ë…¹ìƒ‰ ì¡°ëª…)':
        r, g, b = img.split()
        r = r.point(lambda i: i * 1.1)
        img = Image.merge('RGB', (r, g, b))
    
    # 2. í‘œë©´/ì¬ì§ˆ/ë§ˆë£¨ íŠ¹í™” ë³´ì •
    enhancer_con = ImageEnhance.Contrast(img)
    enhancer_shp = ImageEnhance.Sharpness(img)

    if flooring_mode != 'í•´ë‹¹ ì—†ìŒ':
        # [ë§ˆë£¨ íŠ¹í™”] ì„ ëª…ë„ ëŒ€í­ ê°•í™” (íŒ¨í„´ ì¸ì‹ë¥  í–¥ìƒ)
        img = enhancer_shp.enhance(2.0)
        img = enhancer_con.enhance(1.1)
    else:
        # [ì¼ë°˜ ìì¬] í‘œë©´ ì§ˆê° ë°˜ì˜
        if surface == 'í•˜ì´ê·¸ë¡œì‹œ (ë°˜ì‚¬ ì‹¬í•¨)':
            img = enhancer_con.enhance(1.5) # ëŒ€ë¹„ ê°•í™”
        elif surface == 'ë§¤íŠ¸/ì— ë³´ (ë¬´ê´‘)':
            img = enhancer_con.enhance(1.2) # ëŒ€ë¹„ ì•½ê°„ ê°•í™”
            
        if sharpness != 1.0:
            img = enhancer_shp.enhance(sharpness)
        
    # 3. ë°ê¸° ë³´ì • (ìŠ¬ë¼ì´ë”)
    if brightness != 1.0:
        enhancer_bri = ImageEnhance.Brightness(img)
        img = enhancer_bri.enhance(brightness)
        
    return img

# --- [4] ë©”ì¸ UI ---
st.set_page_config(layout="wide", page_title="ìŠ¤ë§ˆíŠ¸ ìì¬ ê²€ìƒ‰")
st.title("ğŸ­ ìŠ¤ë§ˆíŠ¸ ìì¬ íŒ¨í„´ ê²€ìƒ‰ (í’€ì˜µì…˜)")
st.sidebar.info(f"ğŸ“… ì¬ê³  ê¸°ì¤€ì¼: {stock_date}")

uploaded = st.file_uploader("ìì¬ ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”", type=['jpg', 'png', 'tif', 'jpeg'])

if uploaded:
    st.markdown("### ğŸ› ï¸ ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ë° ì˜ì—­ ì§€ì •")
    
    # [ì˜µì…˜ ë¶€í™œ] ì¡°ëª…, ì¬ì§ˆ, ë§ˆë£¨, ë°ê¸°, ì„ ëª…ë„, íšŒì „ ëª¨ë‘ í¬í•¨
    with st.expander("ğŸ“¸ ì´¬ì˜ í™˜ê²½ ë° ê³ ê¸‰ ì„¤ì • (í´ë¦­í•˜ì—¬ ì—´ê¸°)", expanded=True):
        c1, c2, c3, c4 = st.columns(4)
        with c1:
            source_type = st.radio("ì›ë³¸ ì¢…ë¥˜", ['ì‚¬ì§„ ì´¬ì˜ë³¸', 'ì´ë¯¸ì§€ íŒŒì¼ (ìŠ¤ìº”/ë””ì§€í„¸)'])
        with c2:
            lighting = st.selectbox("ì¡°ëª… ìƒ‰ìƒ", ['ì¼ë°˜/ìì—°ê´‘', 'ë°±ì—´ë“± (ëˆ„ëŸ° ì¡°ëª…)', 'í˜•ê´‘ë“± (í‘¸ë¥¸/ë…¹ìƒ‰ ì¡°ëª…)'], disabled=(source_type!='ì‚¬ì§„ ì´¬ì˜ë³¸'))
        with c3:
            surface = st.selectbox("í‘œë©´ ì¬ì§ˆ", ['ì¼ë°˜', 'í•˜ì´ê·¸ë¡œì‹œ (ë°˜ì‚¬ ì‹¬í•¨)', 'ë§¤íŠ¸/ì— ë³´ (ë¬´ê´‘)'], disabled=(source_type!='ì‚¬ì§„ ì´¬ì˜ë³¸'))
        with c4:
            flooring_mode = st.selectbox("ë§ˆë£¨/ë°”ë‹¥ì¬ ëª¨ë“œ", ['í•´ë‹¹ ì—†ìŒ', 'ì¼ë°˜ ë§ˆë£¨', 'í—¤ë§ë³¸/ì‰ë¸Œë¡ '], disabled=(source_type!='ì‚¬ì§„ ì´¬ì˜ë³¸'))

        c5, c6, c7 = st.columns(3)
        with c5:
            # íšŒì „ì€ ìº”ë²„ìŠ¤ì— ë„£ê¸° ì „ì— PIL ë‹¨ê³„ì—ì„œ ì²˜ë¦¬
            rotation = st.radio("ì‚¬ì§„ íšŒì „", [0, 90, 180, 270], horizontal=True, format_func=lambda x: f"â†©ï¸ {x}ë„" if x else "ì›ë³¸")
        with c6:
            brightness = st.slider("ğŸ’¡ ë°ê¸°", 0.5, 2.0, 1.0, 0.1) if source_type == 'ì‚¬ì§„ ì´¬ì˜ë³¸' else 1.0
        with c7:
            sharpness = st.slider("ğŸ”ª ì„ ëª…ë„", 0.0, 3.0, 1.5, 0.1) if source_type == 'ì‚¬ì§„ ì´¬ì˜ë³¸' else 1.0

    # 1. ì´ë¯¸ì§€ ë¡œë“œ ë° ê¸°ë³¸ íšŒì „ ì ìš©
    original_image = Image.open(uploaded).convert('RGB')
    if rotation != 0:
        original_image = original_image.rotate(-rotation, expand=True)

    # 2. ìº”ë²„ìŠ¤ìš© ë¦¬ì‚¬ì´ì§•
    canvas_width = 600
    w_percent = (canvas_width / float(original_image.size[0]))
    h_size = int((float(original_image.size[1]) * float(w_percent)))
    resized_image = original_image.resize((canvas_width, h_size))
    
    # íŒ ì¶œë ¥
    if flooring_mode == 'í—¤ë§ë³¸/ì‰ë¸Œë¡ ':
        st.info("ğŸ’¡ **[Tip]** í—¤ë§ë³¸ì€ ì—¬ëŸ¬ ìª½ì´ ì„ì—¬ë„ ì¢‹ìœ¼ë‹ˆ **ë„“ê²Œ** ì˜ì—­ì„ ì¡ì•„ì£¼ì„¸ìš”.")
    else:
        st.info("ğŸ‘‡ **ì´ë¯¸ì§€ ìœ„ì—ì„œ [4ê°œ ê¼­ì§€ì ]ì„ ë§ˆìš°ìŠ¤ë¡œ ì½•ì½• ì°ìœ¼ì„¸ìš”.** (ìë™ìœ¼ë¡œ í´ì¤ë‹ˆë‹¤)")

    # 3. ìº”ë²„ìŠ¤ í˜¸ì¶œ (Monkey Patch ë•ë¶„ì— PIL ê°ì²´ ë°”ë¡œ ì‚¬ìš© ê°€ëŠ¥!)
    canvas_result = st_canvas(
        fill_color="rgba(255, 165, 0, 0.3)",
        stroke_width=3,
        stroke_color="#FF0000",
        background_image=resized_image, # ì—¬ê¸°ì„œ ì—ëŸ¬ê°€ ë‚¬ì—ˆì§€ë§Œ ì´ì œ í•´ê²°ë¨!
        update_streamlit=True,
        height=h_size,
        width=canvas_width,
        drawing_mode="polygon",
        key="canvas",
    )

    pts = []
    if canvas_result.json_data is not None:
        objects = canvas_result.json_data["objects"]
        if objects:
            path = objects[-1]["path"]
            for p in path:
                if p[0] == 'L' or p[0] == 'M': pts.append([p[1], p[2]])

    # 4. ì  4ê°œê°€ ì°íˆë©´ ë³€í™˜ ë° ê²€ìƒ‰ ë²„íŠ¼ í™œì„±í™”
    if len(pts) >= 4:
        # íˆ¬ì˜ ë³€í™˜ ìˆ˜í–‰
        pts = np.array(pts[:4], dtype="float32")
        ratio = original_image.size[0] / canvas_width
        original_pts = pts * ratio
        cv_img = np.array(original_image)
        warped = four_point_transform(cv_img, original_pts)
        
        # ë³´ì • í•„í„° ì ìš©
        final_img = Image.fromarray(warped)
        final_img = apply_filters(final_img, source_type, lighting, surface, flooring_mode, brightness, sharpness)
        
        # ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°
        c_res1, c_res2 = st.columns(2)
        with c_res1: st.image(resized_image, caption="ì„ íƒ ì˜ì—­", width=300)
        with c_res2: st.image(final_img, caption="ìµœì¢… ë¶„ì„ ì´ë¯¸ì§€ (ë³´ì •ë¨)", width=300)

        if st.button("ğŸ” ì´ ì¡°ê±´ìœ¼ë¡œ ê²€ìƒ‰ ì‹œì‘", type="primary"):
            with st.spinner('AI ë¶„ì„ ì¤‘...'):
                x = image.img_to_array(final_img.resize((224, 224)))
                x = np.expand_dims(x, axis=0)
                query_vec = model.predict(preprocess_input(x), verbose=0).flatten().reshape(1, -1)
                
                db_names, db_vecs = list(feature_db.keys()), np.array(list(feature_db.values()))
                sims = cosine_similarity(query_vec, db_vecs).flatten()
                
                results = []
                for i in range(len(db_names)):
                    fname = db_names[i]
                    info = master_map.get(get_digits(fname), {'formal': fname, 'name': 'ì •ë³´ ì—†ìŒ'})
                    formal = info['formal']
                    qty = agg_stock.get(formal.strip().upper(), 0)
                    
                    url_row = df_path[df_path['ì¶”ì¶œëœ_í’ˆë²ˆ'].apply(get_digits) == get_digits(fname)]
                    if url_row.empty: url_row = df_path[df_path['íŒŒì¼ëª…'] == fname]
                    url = url_row['ì¹´ì¹´ì˜¤í†¡_ì „ì†¡ìš©_URL'].values[0] if not url_row.empty else None
                    
                    results.append({'formal': formal, 'name': info['name'], 'score': sims[i], 'stock': qty, 'url': url})
                
                results = sorted(results, key=lambda x: x['score'], reverse=True)
                st.session_state['search_results'] = results
                st.session_state['search_done'] = True

    # 5. ê²°ê³¼ ì¶œë ¥
    if st.session_state.get('search_done'):
        st.markdown("---")
        results = st.session_state['search_results']
        
        def display_card(item, idx):
            st.markdown(f"**{idx}. {item['formal']}**")
            st.write(f"{item['name']}")
            st.caption(f"ìœ ì‚¬ë„: {item['score']:.1%}")
            if item['url']:
                st.markdown(f"ğŸ”— [**ê³ í™”ì§ˆ ì›ë³¸**]({item['url']})")
                with st.expander("ğŸ–¼ï¸ í¼ì¹˜ê¸°", expanded=False):
                    try:
                        r = requests.get(get_direct_url(item['url']), timeout=5)
                        st.image(Image.open(BytesIO(r.content)), use_container_width=True)
                    except: st.write("ë¡œë”© ì‹¤íŒ¨")
            else: st.write("ì´ë¯¸ì§€ ì—†ìŒ")
            
            if item['stock'] >= 100: st.success(f"ì¬ê³ : {item['stock']:,}m")
            else: st.write(f"ì¬ê³ : {item['stock']:,}m")

        t1, t2 = st.tabs(["ğŸ“Š ì „ì²´ ê²°ê³¼", "âœ… ì¬ê³  ë³´ìœ  (100mâ†‘)"])
        with t1:
            cols = st.columns(5)
            for i, r in enumerate(results[:10]):
                with cols[i%5]: display_card(r, i+1)
        with t2:
            hits = [r for r in results if r['stock'] >= 100]
            if hits:
                cols = st.columns(5)
                for i, r in enumerate(hits[:10]):
                    with cols[i%5]: display_card(r, i+1)
            else: st.warning("ì¬ê³  ë³´ìœ  ìì¬ ì—†ìŒ")
