import streamlit as st
import pandas as pd
import pickle
import numpy as np
import re
import os
import requests
import cv2
import base64
import time
from PIL import Image, ImageEnhance, ImageDraw
from io import BytesIO
from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input
from tensorflow.keras.preprocessing import image
from sklearn.metrics.pairwise import cosine_similarity
from streamlit_image_coordinates import streamlit_image_coordinates

# -----------------------------------------------------------
# ğŸš‘ [í•„ìˆ˜ íŒ¨ì¹˜] Streamlit í˜¸í™˜ì„± ë° ì´ë¯¸ì§€ ì¶œë ¥ ì•ˆì •í™”
# -----------------------------------------------------------
import streamlit.elements.image as st_image

def local_image_to_url(image, width=None, clamp=False, channels="RGB", output_format="auto", image_id=None):
    buffered = BytesIO()
    image.save(buffered, format="PNG")
    img_str = base64.b64encode(buffered.getvalue()).decode()
    return f"data:image/png;base64,{img_str}"

if not hasattr(st_image, 'image_to_url'):
    st_image.image_to_url = local_image_to_url

# --- [1] ìœ í‹¸ë¦¬í‹° ë° ë¦¬ì†ŒìŠ¤ ---
def get_direct_url(url):
    if not url or str(url) == 'nan' or 'drive.google.com' not in url: return url
    if 'file/d/' in url: file_id = url.split('file/d/')[1].split('/')[0]
    elif 'id=' in url: file_id = url.split('id=')[1].split('&')[0]
    else: return url
    return f'https://drive.google.com/uc?export=download&id={file_id}'

def load_csv_smart(target_name):
    files = os.listdir('.')
    for f in files:
        if f.lower() == target_name.lower():
            for enc in ['utf-8-sig', 'utf-8', 'cp949', 'euc-kr']:
                try: return pd.read_csv(f, encoding=enc)
                except: continue
    st.error(f"âŒ {target_name} íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    st.stop()

def get_digits(text):
    return "".join(re.findall(r'\d+', str(text))) if text else ""

def is_formal_code(code):
    if not code or pd.isna(code): return False
    pattern = r'^\d+-\d+-\d+$'
    return bool(re.match(pattern, str(code).strip()))

@st.cache_resource
def init_resources():
    model = ResNet50(weights='imagenet', include_top=False, pooling='avg')
    with open('material_features.pkl', 'rb') as f:
        feature_db = pickle.load(f)
    df_path = load_csv_smart('ì´ë¯¸ì§€ê²½ë¡œ.csv')
    df_info = load_csv_smart('í’ˆëª©ì •ë³´.csv')
    df_stock = load_csv_smart('í˜„ì¬ê³ .csv')
    
    # ğŸš€ [ì¬ê³  ë¡œì§ ìœ ì§€] strip().upper()ë¥¼ ì‚¬ìš©í•œ ì •ë°€ ë§¤ì¹­
    df_stock['ì¬ê³ ìˆ˜ëŸ‰'] = pd.to_numeric(df_stock['ì¬ê³ ìˆ˜ëŸ‰'].astype(str).str.replace(',', ''), errors='coerce').fillna(0)
    df_stock['í’ˆë²ˆ_KEY'] = df_stock['í’ˆë²ˆ'].astype(str).str.strip().str.upper()
    agg_stock = df_stock.groupby('í’ˆë²ˆ_KEY')['ì¬ê³ ìˆ˜ëŸ‰'].sum().to_dict()
    stock_date = str(int(df_stock['ì •ì‚°ì¼ì'].max())) if 'ì •ì‚°ì¼ì' in df_stock.columns else "í™•ì¸ë¶ˆê°€"
    
    valid_keys = set(df_path['ì¶”ì¶œëœ_í’ˆë²ˆ'].apply(get_digits).unique())
    filtered_db = {k: v for k, v in feature_db.items() if get_digits(k) in valid_keys}
    
    return model, filtered_db, df_path, df_info, agg_stock, stock_date

model, feature_db, df_path, df_info, agg_stock, stock_date = init_resources()

@st.cache_data
def get_master_map():
    mapping = {}
    for _, row in df_info.iterrows():
        f = str(row['ìƒí’ˆì½”ë“œ']).strip() if pd.notna(row.get('ìƒí’ˆì½”ë“œ')) else ''
        l = str(row.get('Lab No', '')).strip() if pd.notna(row.get('Lab No')) else ''
        n = str(row.get('ìƒí’ˆëª…', '')).strip() if pd.notna(row.get('ìƒí’ˆëª…')) else ''
        current_formal = f if f else l
        info = {'formal': current_formal, 'name': n, 'lab_no': l}
        keys = set()
        for v in [f, l]:
            d = get_digits(v)
            if d: keys.add(d)
        for k in keys:
            if k not in mapping or (is_formal_code(current_formal) and not is_formal_code(mapping[k]['formal'])):
                mapping[k] = info
    return mapping

master_map = get_master_map()

# --- [2] ì´ë¯¸ì§€ ì²˜ë¦¬ í•¨ìˆ˜ ---
def order_points(pts):
    rect = np.zeros((4, 2), dtype="float32")
    s = pts.sum(axis=1); rect[0] = pts[np.argmin(s)]; rect[2] = pts[np.argmax(s)]
    diff = np.diff(pts, axis=1); rect[1] = pts[np.argmin(diff)]; rect[3] = pts[np.argmax(diff)]
    return rect

def four_point_transform(image, pts):
    rect = order_points(pts)
    (tl, tr, br, bl) = rect
    widthA = np.sqrt(((br[0] - bl[0]) ** 2) + ((br[1] - bl[1]) ** 2))
    widthB = np.sqrt(((tr[0] - tl[0]) ** 2) + ((tr[1] - tl[1]) ** 2))
    maxWidth = max(int(widthA), int(widthB))
    heightA = np.sqrt(((tr[0] - br[0]) ** 2) + ((tr[1] - br[1]) ** 2))
    heightB = np.sqrt(((tl[0] - bl[0]) ** 2) + ((tl[1] - bl[1]) ** 2))
    maxHeight = max(int(heightA), int(heightB))
    dst = np.array([[0, 0], [maxWidth - 1, 0], [maxWidth - 1, maxHeight - 1], [0, maxHeight - 1]], dtype="float32")
    M = cv2.getPerspectiveTransform(rect, dst)
    return cv2.warpPerspective(image, M, (maxWidth, maxHeight))

# ğŸš€ [ìŠ¤ë§ˆíŠ¸ í•„í„° ìˆ˜ì¹˜ ìœ ì§€] ì„¸ì´ë¸Œí¬ì¸íŠ¸ ìˆ˜ì¹˜
def apply_smart_filters(img, category, lighting, brightness, sharpness):
    if lighting == 'ë°±ì—´ë“± (ëˆ„ëŸ° ì¡°ëª…)':
        r, g, b = img.split(); b = b.point(lambda i: i * 1.2); img = Image.merge('RGB', (r, g, b))
    elif lighting == 'í˜•ê´‘ë“± (í‘¸ë¥¸/ë…¹ìƒ‰ ì¡°ëª…)':
        r, g, b = img.split(); r = r.point(lambda i: i * 1.1); img = Image.merge('RGB', (r, g, b))
    
    en_con = ImageEnhance.Contrast(img); en_shp = ImageEnhance.Sharpness(img); en_bri = ImageEnhance.Brightness(img); en_col = ImageEnhance.Color(img)
    
    if category == 'ë§ˆë£¨/ìš°ë“œ (Wood)':
        img = en_shp.enhance(2.0); img = en_con.enhance(1.1)
    elif category == 'í•˜ì´ê·¸ë¡œì‹œ/ìœ ê´‘ (Glossy)':
        img = en_con.enhance(1.5); img = en_shp.enhance(1.2)
    elif category == 'ë²½ì§€/íŒ¨ë¸Œë¦­ (Texture)':
        img = en_shp.enhance(1.5); img = en_bri.enhance(1.1)
    elif category == 'ì„ì¬/ì½˜í¬ë¦¬íŠ¸ (Stone)':
        img = en_col.enhance(0.8); img = en_shp.enhance(1.5)
    
    if brightness != 1.0: img = en_bri.enhance(brightness)
    if sharpness != 1.0: img = en_shp.enhance(sharpness)
    return img

# --- [3] ë©”ì¸ UI ---
st.set_page_config(layout="wide", page_title="ìŠ¤ë§ˆíŠ¸ ìì¬ íŒ¨í„´ ê²€ìƒ‰")
st.title("ğŸ­ ìŠ¤ë§ˆíŠ¸ ìì¬ íŒ¨í„´ ê²€ìƒ‰")
st.sidebar.info(f"ğŸ“… ì¬ê³  ê¸°ì¤€ì¼: {stock_date}")

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if 'points' not in st.session_state: st.session_state['points'] = []
if 'search_done' not in st.session_state: st.session_state['search_done'] = False
if 'upload_ready' not in st.session_state: st.session_state['upload_ready'] = False
if 'refresh_count' not in st.session_state: st.session_state['refresh_count'] = 0

# ğŸš€ [íˆíŠ¸ë¹„íŠ¸ ì œê±°] ì—…ë¡œë“œ ì¤€ë¹„ ë²„íŠ¼ë§Œ ìœ ì§€
if not st.session_state['upload_ready']:
    st.warning("ğŸ“± ëª¨ë°”ì¼ í™˜ê²½ì—ì„œëŠ” 'ì¤€ë¹„ ì‹œì‘' ë²„íŠ¼ì„ ëˆŒëŸ¬ ì—°ê²°ì„ í™œì„±í™”í•˜ì„¸ìš”.")
    if st.button("ğŸš€ ì—…ë¡œë“œ ì¤€ë¹„ ì‹œì‘"):
        st.session_state['upload_ready'] = True
        st.rerun()
else:
    uploaded = st.file_uploader("ğŸ“¸ ì‚¬ì§„ ì—…ë¡œë“œ", type=['jpg','png','jpeg'], key=f"up_v25")

    if st.sidebar.button("ğŸ”„ ì „ì²´ ì´ˆê¸°í™”"):
        st.session_state.clear()
        st.rerun()

    if uploaded:
        if 'current_img_name' not in st.session_state or st.session_state['current_img_name'] != uploaded.name:
            st.session_state['points'] = []; st.session_state['search_done'] = False
            st.session_state['current_img_name'] = uploaded.name
            with st.spinner('ğŸ“¸ ê³ í™”ì§ˆ ì²˜ë¦¬ ì¤‘...'):
                raw = Image.open(uploaded).convert('RGB')
                # ğŸš€ [ê³ í™”ì§ˆ ìƒí–¥] ê¸°ì¡´ 1200ì—ì„œ 1600ìœ¼ë¡œ í™•ëŒ€
                raw.thumbnail((1600, 1600), Image.Resampling.LANCZOS)
                st.session_state['proc_img'] = raw
            st.rerun()

        working_img = st.session_state['proc_img']
        
        st.markdown("### 1ï¸âƒ£ í™˜ê²½ ì„¤ì •")
        source_type = st.radio("ğŸ“‚ ì›ë³¸ ì¢…ë¥˜", ['ğŸ“¸ í˜„ì¥ ì‚¬ì§„', 'ğŸ’» ë””ì§€í„¸ íŒŒì¼'], horizontal=True)
        is_photo = (source_type == 'ğŸ“¸ í˜„ì¥ ì‚¬ì§„')
        
        c_opt1, c_opt2 = st.columns(2)
        with c_opt1: mat_type = st.selectbox("ğŸ§± ìì¬ ì¢…ë¥˜", ['ì¼ë°˜', 'ë§ˆë£¨/ìš°ë“œ (Wood)', 'í•˜ì´ê·¸ë¡œì‹œ/ìœ ê´‘ (Glossy)', 'ë²½ì§€/íŒ¨ë¸Œë¦­ (Texture)', 'ì„ì¬/ì½˜í¬ë¦¬íŠ¸ (Stone)'], disabled=not is_photo)
        with c_opt2: s_mode = st.radio("ğŸ” ê²€ìƒ‰ ê¸°ì¤€", ["ğŸ¨ ì»¬ëŸ¬+íŒ¨í„´ ì¢…í•©", "ğŸ¦“ íŒ¨í„´ ì¤‘ì‹¬ (í‘ë°±)"], horizontal=True)

        with st.expander("âš™ï¸ ê³ ê¸‰ ì„¤ì •", expanded=False):
            c1, c2, c3 = st.columns(3)
            with c1: lighting = st.selectbox("ì¡°ëª…", ['ì¼ë°˜/ìì—°ê´‘', 'ë°±ì—´ë“± (ëˆ„ëŸ° ì¡°ëª…)', 'í˜•ê´‘ë“± (í‘¸ë¥¸/ë…¹ìƒ‰ ì¡°ëª…)'], disabled=not is_photo)
            with c2: 
                if st.button("â†©ï¸ 90ë„ íšŒì „"): 
                    st.session_state['proc_img'] = working_img.rotate(90, expand=True)
                    st.session_state['points'] = []; st.rerun()
            with c3:
                bri = st.slider("ë°ê¸°", 0.5, 2.0, 1.0, 0.1, disabled=not is_photo)
                shp = st.slider("ì„ ëª…ë„", 0.0, 3.0, 1.5, 0.1, disabled=not is_photo)

        st.markdown("### 2ï¸âƒ£ ì˜ì—­ ì§€ì •")
        
        # ğŸš€ [ê¸°ë³¸ê°’ 70% ì„¤ì •] Radio ë²„íŠ¼ ë°©ì‹ ìœ ì§€
        scale_val = st.radio("ğŸ” ë³´ê¸° í¬ê¸° (ëª¨ë°”ì¼ ì¡°ì‘ ìµœì í™”):", [0.3, 0.5, 0.7, 1.0], format_func=lambda x: f"{int(x*100)}%", index=2, horizontal=True)

        c_ref, c_del, c_auto = st.columns([1, 1, 2])
        with c_ref: 
            # ğŸš€ [ìƒˆë¡œê³ ì¹¨ ê°œì„ ] í´ë¦­ ì‹œ ë¦¬í”„ë ˆì‹œ ì¹´ìš´íŠ¸ë¥¼ ì˜¬ë ¤ ì»´í¬ë„ŒíŠ¸ ê°•ì œ ê°±ì‹ 
            if st.button("ğŸ”„ ì´ë¯¸ì§€ ì•ˆë‚˜ì˜´"):
                st.session_state['refresh_count'] += 1
                st.toast("ì´ë¯¸ì§€ë¥¼ ë‹¤ì‹œ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤...")
                st.rerun()
        with c_del:
            if st.button("âŒ ì  ì§€ìš°ê¸°", type="secondary"):
                st.session_state['points'] = []; st.rerun()
        with c_auto:
            if st.button("â¹ï¸ ì „ì²´ ì„ íƒ", type="primary"):
                w, h = working_img.size
                st.session_state['points'] = [(0, 0), (w, 0), (w, h), (0, h)]; st.rerun()

        # í‘œì‹œìš© ì´ë¯¸ì§€ (ìŠ¤ì¼€ì¼ ë°˜ì˜)
        w, h = working_img.size
        d_img = working_img.resize((int(w * scale_val), int(h * scale_val)), Image.Resampling.LANCZOS)
        draw = ImageDraw.Draw(d_img)
        
        # í¬ì¸íŠ¸ ë²ˆí˜¸ í‘œì‹œ ìœ ì§€
        for i, p in enumerate(st.session_state['points']):
            px, py = p[0] * scale_val, p[1] * scale_val
            draw.ellipse((px-8, py-8, px+8, py+8), fill='red', outline='white', width=2)
            draw.text((px + 10, py - 10), str(i + 1), fill='red')

        if len(st.session_state['points']) == 4:
            pts_s = [(p[0]*scale_val, p[1]*scale_val) for p in st.session_state['points']]
            draw.polygon([tuple(p) for p in order_points(np.array(pts_s))], outline='#00FF00', width=3)

        # ğŸš€ [ì´ë¯¸ì§€ ê°•ì œ ë Œë”ë§] refresh_countë¥¼ í‚¤ì— í¬í•¨í•˜ì—¬ ë²„íŠ¼ í´ë¦­ ì‹œ ë¬´ì¡°ê±´ ë‹¤ì‹œ ê·¸ë¦¬ê²Œ í•¨
        value = streamlit_image_coordinates(d_img, key=f"click_pad_{st.session_state['refresh_count']}")
        
        if value:
            rx, ry = value['x'] / scale_val, value['y'] / scale_val
            if len(st.session_state['points']) < 4:
                new_p = (rx, ry)
                if not st.session_state['points'] or st.session_state['points'][-1] != new_p:
                    st.session_state['points'].append(new_p); st.rerun()

        # ë¯¸ë¦¬ë³´ê¸° ì˜ì—­ ìœ ì§€
        if len(st.session_state['points']) == 4:
            st.markdown("#### ğŸ” ë¶„ì„ ì˜ì—­ ë¯¸ë¦¬ë³´ê¸°")
            warped = four_point_transform(np.array(working_img), np.array(st.session_state['points'], dtype="float32"))
            final_img = Image.fromarray(warped)
            if is_photo: final_img = apply_smart_filters(final_img, mat_type, lighting, bri, shp)
            if s_mode == "ğŸ¦“ íŒ¨í„´ ì¤‘ì‹¬ (í‘ë°±)": final_img = final_img.convert("L").convert("RGB")
            
            st.image(final_img, width=300, caption="ì´ ì˜ì—­ì„ ë¶„ì„í•©ë‹ˆë‹¤")

            if st.button("ğŸ” ì´ íŒ¨í„´ìœ¼ë¡œ ê²€ìƒ‰ ì‹œì‘", type="primary", use_container_width=True):
                with st.spinner('ìœ ì‚¬ ìì¬ ì°¾ëŠ” ì¤‘...'):
                    x = image.img_to_array(final_img.resize((224, 224)))
                    q_vec = model.predict(preprocess_input(np.expand_dims(x, axis=0)), verbose=0).flatten().reshape(1, -1)
                    db_n = list(feature_db.keys()); db_v = np.array(list(feature_db.values()))
                    sims = cosine_similarity(q_vec, db_v).flatten()
                    
                    all_r, stock_r = [], []
                    seen_all, seen_stock = set(), set()
                    idx_sort = np.argsort(sims)[::-1]
                    
                    for i in idx_sort:
                        fn = db_n[i]
                        info = master_map.get(get_digits(fn), {'formal': fn, 'name': 'ì •ë³´ ì—†ìŒ'})
                        f_code = info['formal']
                        f_key = f_code.strip().upper()
                        qty = agg_stock.get(f_key, 0)
                        
                        u_row = df_path[df_path['ì¶”ì¶œëœ_í’ˆë²ˆ'].apply(get_digits) == get_digits(fn)]
                        url = u_row['ì¹´ì¹´ì˜¤í†¡_ì „ì†¡ìš©_URL'].values[0] if not url_row.empty else None
                        
                        if url:
                            data = {'formal': f_code, 'name': info['name'], 'score': sims[i], 'stock': qty, 'url': url}
                            if f_code not in seen_all and len(all_r) < 15:
                                all_r.append(data); seen_all.add(f_code)
                            if qty >= 100 and f_code not in seen_stock and len(stock_r) < 15:
                                stock_r.append(data); seen_stock.add(f_code)
                    
                    st.session_state['search_results'] = {'all': all_r, 'stock': stock_r}
                    st.session_state['search_done'] = True; st.rerun()

    if st.session_state.get('search_done'):
        st.markdown("---")
        res_data = st.session_state['search_results']
        def draw_card(item, idx):
            st.markdown(f"**{idx}. {item['formal']}**")
            st.caption(f"{item['name']} (ìœ ì‚¬ë„: {item['score']:.1%})")
            with st.expander("ğŸ–¼ï¸ ì´ë¯¸ì§€ í™•ì¸", expanded=False):
                try:
                    r = requests.get(get_direct_url(item['url']), timeout=5)
                    st.image(Image.open(BytesIO(r.content)), use_container_width=True)
                except: st.write("âš ï¸ ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨")
            if item['stock'] >= 100: st.success(f"ì¬ê³ : {item['stock']:,}m")
            else: st.info(f"ì¬ê³ : {item['stock']:,}m")

        t1, t2 = st.tabs(["ğŸ“Š ì „ì²´ ê²°ê³¼", "âœ… ì¬ê³  ë³´ìœ  (100mâ†‘)"])
        with t1:
            cols = st.columns(5)
            for i, r in enumerate(res_data['all']):
                with cols[i%5]: draw_card(r, i+1)
        with t2:
            if res_data['stock']:
                cols = st.columns(5)
                for i, r in enumerate(res_data['stock']):
                    with cols[i%5]: draw_card(r, i+1)
            else: st.warning("âš ï¸ ì¬ê³  100m ì´ìƒì¸ ìœ ì‚¬ ìì¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
