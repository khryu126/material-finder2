import streamlit as st
import pandas as pd
import pickle
import numpy as np
import re
import os
import requests
import cv2
import base64
from PIL import Image, ImageEnhance, ImageDraw, ImageFilter, ImageOps
from io import BytesIO
from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input
from tensorflow.keras.preprocessing import image
from sklearn.metrics.pairwise import cosine_similarity
from streamlit_image_coordinates import streamlit_image_coordinates

# -----------------------------------------------------------
# ğŸš‘ [ì‹œìŠ¤í…œ íŒ¨ì¹˜] Streamlit ì´ë¯¸ì§€ ë Œë”ë§ í˜¸í™˜ì„± í•´ê²°
# -----------------------------------------------------------
import streamlit.elements.image as st_image

def local_image_to_url(image, width=None, clamp=False, channels="RGB", output_format="auto", image_id=None):
    buffered = BytesIO()
    image.save(buffered, format="PNG")
    img_str = base64.b64encode(buffered.getvalue()).decode()
    return f"data:image/png;base64,{img_str}"

if not hasattr(st_image, 'image_to_url'):
    st_image.image_to_url = local_image_to_url

# -----------------------------------------------------------
# --- [1] ìœ í‹¸ë¦¬í‹° ë° ë°ì´í„° ë§¤í•‘ ë¡œì§ (í•©ë¦¬ì  ë¡œì§ ì ìš©) ---
# -----------------------------------------------------------

def get_direct_url(url):
    """êµ¬ê¸€ ë“œë¼ì´ë¸Œ URL ë³€í™˜ (ì•ˆì •ì  ë‹¤ìš´ë¡œë“œ ë§í¬)"""
    if not url or str(url) == 'nan' or 'drive.google.com' not in url: 
        return url
    file_id = ""
    if 'file/d/' in url: file_id = url.split('file/d/')[1].split('/')[0]
    elif 'id=' in url: file_id = url.split('id=')[1].split('&')[0]
    return f'https://drive.google.com/uc?export=download&id={file_id}' if file_id else url

def is_formal_code(code):
    """ì •ì‹ í’ˆë²ˆ(14-54130-119 ë“±) í˜•ì‹ ê²€ì‚¬"""
    if not code or pd.isna(code): return False
    return bool(re.match(r'^\d+-\d+-\d+$', str(code).strip()))

def extract_digits(text):
    """4ìë¦¬ ì´ìƒ í•µì‹¬ ìˆ«ì ì¶”ì¶œ (ë§¤ì¹­ í‚¤)"""
    if pd.isna(text) or str(text).strip() == '-': return ""
    nums = re.findall(r'\d{4,}', str(text))
    return nums[0] if nums else ""

@st.cache_resource
def init_resources():
    model = ResNet50(weights='imagenet', include_top=False, pooling='avg')
    if os.path.exists('material_features.pkl'):
        with open('material_features.pkl', 'rb') as f: feature_db = pickle.load(f)
    else:
        st.error("âŒ material_features.pkl íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        st.stop()

    def load_csv(name):
        for enc in ['utf-8-sig', 'utf-8', 'cp949', 'euc-kr']:
            try: return pd.read_csv(name, encoding=enc)
            except: continue
        return None

    df_path, df_info, df_stock = load_csv('ì´ë¯¸ì§€ê²½ë¡œ.csv'), load_csv('í’ˆëª©ì •ë³´.csv'), load_csv('í˜„ì¬ê³ .csv')
    
    # ì¬ê³  ë°ì´í„° ì „ì²˜ë¦¬
    df_stock['ì¬ê³ ìˆ˜ëŸ‰'] = pd.to_numeric(df_stock['ì¬ê³ ìˆ˜ëŸ‰'].astype(str).str.replace(',', ''), errors='coerce').fillna(0)
    df_stock['í’ˆë²ˆ_KEY'] = df_stock['í’ˆë²ˆ'].apply(extract_digits)
    agg_stock = df_stock.groupby('í’ˆë²ˆ_KEY')['ì¬ê³ ìˆ˜ëŸ‰'].sum().to_dict()
    stock_date = str(int(df_stock['ì •ì‚°ì¼ì'].max())) if 'ì •ì‚°ì¼ì' in df_stock.columns else "í™•ì¸ë¶ˆê°€"
    
    return model, feature_db, df_path, df_info, agg_stock, stock_date

model, feature_db, df_path, df_info, agg_stock, stock_date = init_resources()

@st.cache_data
def get_master_map():
    """í’ˆë²ˆ ìš°ì„ ìˆœìœ„ ì ìš© ë§¤í•‘ (ì •ì‹ ê·œê²© ìš°ì„ )"""
    mapping = {}
    for _, row in df_info.iterrows():
        f = str(row.get('ìƒí’ˆì½”ë“œ', '')).strip()
        l = str(row.get('Lab No', '')).strip()
        n = str(row.get('ìƒí’ˆëª…', '')).strip()
        
        info = {'formal': f if f else l, 'name': n, 'lab_no': l}
        
        # ë§¤ì¹­ í‚¤ ìƒì„± (ìˆ«ì ì¤‘ì‹¬)
        keys = {extract_digits(f), extract_digits(l), f, l}
        for k in keys:
            if not k: continue
            if k not in mapping:
                mapping[k] = info
            else:
                # ğŸš€ ì •ì‹ ê·œê²©(14-...)ì´ ë‚˜íƒ€ë‚˜ë©´ ê¸°ì¡´ì˜ ì„ì‹œ ë²ˆí˜¸ ì •ë³´ë¥¼ êµì²´
                if is_formal_code(info['formal']) and not is_formal_code(mapping[k]['formal']):
                    mapping[k] = info
    return mapping

master_map = get_master_map()

# -----------------------------------------------------------
# --- [2] ì´ë¯¸ì§€ ë¶„ì„ ë° ë³€í™˜ ë¡œì§ ---
# -----------------------------------------------------------

def apply_smart_filters(img, category, lighting, brightness, sharpness):
    if lighting == 'ë°±ì—´ë“± (ëˆ„ëŸ° ì¡°ëª…)':
        r, g, b = img.split()
        b = b.point(lambda i: i * 1.2)
        img = Image.merge('RGB', (r, g, b))
    elif lighting == 'í˜•ê´‘ë“± (í‘¸ë¥¸/ë…¹ìƒ‰ ì¡°ëª…)':
        r, g, b = img.split()
        r = r.point(lambda i: i * 1.1)
        img = Image.merge('RGB', (r, g, b))

    enhancer_con = ImageEnhance.Contrast(img)
    enhancer_shp = ImageEnhance.Sharpness(img)
    enhancer_bri = ImageEnhance.Brightness(img)
    
    if category == 'ë§ˆë£¨/ìš°ë“œ (Wood)': img = enhancer_shp.enhance(2.0)
    elif category == 'í•˜ì´ê·¸ë¡œì‹œ/ìœ ê´‘ (Glossy)': img = enhancer_con.enhance(1.5)
    
    if brightness != 1.0: img = enhancer_bri.enhance(brightness)
    if sharpness != 1.5: img = enhancer_shp.enhance(sharpness)
    return img

def prepare_image_for_ai(img, mode):
    """ì´ë¯¸ì§€ ì „ì²˜ë¦¬: ëŒ€ë¹„ ì •ê·œí™”ë¡œ ìƒ‰ìƒ/ë°ê¸° í¸ì°¨ ê·¹ë³µ"""
    img = img.resize((224, 224))
    if mode == "ğŸ¦“ íŒ¨í„´/ì§ˆê° ì¤‘ì‹¬ (ìƒ‰ìƒ ë¬´ì‹œ)":
        img = img.convert("L").convert("RGB")
    elif mode == "ğŸ¨ ì»¬ëŸ¬ ì¤‘ì‹¬ (íŒ¨í„´ ë­‰ê°œê¸°)":
        img = img.filter(ImageFilter.GaussianBlur(radius=15))
    else:
        # ëŒ€ë¹„ ì •ê·œí™”: ë°ì€ ìƒ˜í”Œê³¼ ì–´ë‘ìš´ ìƒ˜í”Œ ê°„ì˜ ì°¨ì´ë¥¼ ì¤„ì—¬ì¤Œ
        img = ImageOps.autocontrast(img, cutoff=1)
    return img

def order_points(pts):
    rect = np.zeros((4, 2), dtype="float32")
    s = pts.sum(axis=1); rect[0], rect[2] = pts[np.argmin(s)], pts[np.argmax(s)]
    diff = np.diff(pts, axis=1); rect[1], rect[3] = pts[np.argmin(diff)], pts[np.argmax(diff)]
    return rect

def four_point_transform(image, pts):
    rect = order_points(pts)
    (tl, tr, br, bl) = rect
    w = max(int(np.sqrt(((br[0]-bl[0])**2) + ((br[1]-bl[1])**2))), int(np.sqrt(((tr[0]-tl[0])**2) + ((tr[1]-tl[1])**2))))
    h = max(int(np.sqrt(((tr[0]-br[0])**2) + ((tr[1]-br[1])**2))), int(np.sqrt(((tl[0]-bl[0])**2) + ((tl[1]-bl[1])**2))))
    dst = np.array([[0, 0], [w - 1, 0], [w - 1, h - 1], [0, h - 1]], dtype="float32")
    M = cv2.getPerspectiveTransform(rect, dst)
    return cv2.warpPerspective(image, M, (w, h))

# -----------------------------------------------------------
# --- [3] ë©”ì¸ UI (ê¸°ëŠ¥ ì™„ì „ ë³µêµ¬) ---
# -----------------------------------------------------------

st.set_page_config(layout="wide", page_title="ìŠ¤ë§ˆíŠ¸ ìì¬ ê²€ìƒ‰")
st.title("ğŸ­ ìŠ¤ë§ˆíŠ¸ ìì¬ íŒ¨í„´ ê²€ìƒ‰")

st.sidebar.info(f"ğŸ“… ì¬ê³  ê¸°ì¤€ì¼: {stock_date}")
if st.sidebar.button("ğŸ”„ ì²˜ìŒë¶€í„° ë‹¤ì‹œ í•˜ê¸° (Reset)"):
    for key in ['points', 'search_done', 'search_results', 'raw_img', 'current_img_name']:
        if key in st.session_state: del st.session_state[key]
    st.rerun()

tab1, tab2 = st.tabs(["ğŸ“‚ íŒŒì¼ ì—…ë¡œë“œ", "ğŸ“¸ ì¹´ë©”ë¼ ì´¬ì˜"])
input_file = None
active_source = None
with tab1:
    uploaded = st.file_uploader("ì´ë¯¸ì§€ íŒŒì¼ ì„ íƒ", type=['jpg', 'png', 'jpeg'], key="up")
    if uploaded: input_file, active_source = uploaded, "upload"
with tab2:
    camera_shot = st.camera_input("ì¹´ë©”ë¼ë¡œ ì°ê¸°")
    if camera_shot: input_file, active_source = camera_shot, "camera"

if input_file:
    file_id = input_file.name if hasattr(input_file, 'name') else "camera_img"
    if 'current_img_name' not in st.session_state or st.session_state['current_img_name'] != file_id:
        st.session_state['raw_img'] = Image.open(input_file).convert('RGB')
        st.session_state['current_img_name'] = file_id
        st.session_state['points'] = []
        st.session_state['search_done'] = False

    raw = st.session_state['raw_img']
    
    st.markdown("### 1ï¸âƒ£ í™˜ê²½ ë° ê²€ìƒ‰ ì„¤ì •")
    c_set1, c_set2 = st.columns(2)
    with c_set1:
        source_type = st.radio("ğŸ“‚ ì›ë³¸ ì¢…ë¥˜", ['ğŸ“¸ í˜„ì¥ ì´¬ì˜ ì‚¬ì§„', 'ğŸ’» ì´ë¯¸ì§€ íŒŒì¼ (ìŠ¤ìº”/ë””ì§€í„¸)'], horizontal=True)
        is_photo = (source_type == 'ğŸ“¸ í˜„ì¥ ì´¬ì˜ ì‚¬ì§„')
    with c_set2:
        search_mode = st.radio("ğŸ” ê²€ìƒ‰ ê¸°ì¤€", ["ğŸ¨ ì»¬ëŸ¬ + íŒ¨í„´ ì¢…í•©", "ğŸ¦“ íŒ¨í„´/ì§ˆê° ì¤‘ì‹¬ (ìƒ‰ìƒ ë¬´ì‹œ)", "ğŸ¨ ì»¬ëŸ¬ ì¤‘ì‹¬ (íŒ¨í„´ ë­‰ê°œê¸°)"], horizontal=True)

    # ğŸš€ [ë³µêµ¬] ì„¸ë¶€ ë³´ì • ì˜µì…˜ (Expander)
    with st.expander("âš™ï¸ ì„¸ë¶€ ë³´ì • ë° íšŒì „ (ì¡°ëª…, ë°ê¸°, ì„ ëª…ë„)", expanded=is_photo):
        col_ex1, col_ex2, col_ex3 = st.columns(3)
        with col_ex1:
            material_type = st.selectbox("ğŸ§± ìì¬ ì¢…ë¥˜", ['ì¼ë°˜ (ê¸°ë³¸)', 'ë§ˆë£¨/ìš°ë“œ (Wood)', 'í•˜ì´ê·¸ë¡œì‹œ/ìœ ê´‘ (Glossy)', 'ë²½ì§€/íŒ¨ë¸Œë¦­ (Texture)', 'ì„ì¬/ì½˜í¬ë¦¬íŠ¸ (Stone)'], disabled=not is_photo)
            lighting = st.selectbox("ğŸ’¡ ì¡°ëª… ë³´ì •", ['ì¼ë°˜/ìì—°ê´‘', 'ë°±ì—´ë“± (ëˆ„ëŸ° ì¡°ëª…)', 'í˜•ê´‘ë“± (í‘¸ë¥¸/ë…¹ìƒ‰ ì¡°ëª…)'], disabled=not is_photo)
        with col_ex2:
            st.write("") 
            if st.button("â†©ï¸ ì‚¬ì§„ 90ë„ íšŒì „"):
                st.session_state['raw_img'] = raw.rotate(90, expand=True)
                st.session_state['points'] = []
                st.rerun()
        with col_ex3:
            brightness = st.slider("â˜€ï¸ ë°ê¸°", 0.5, 2.0, 1.0, 0.1, disabled=not is_photo)
            sharpness = st.slider("ğŸ”ª ì„ ëª…ë„", 0.0, 3.0, 1.5, 0.1, disabled=not is_photo)

    st.markdown("### 2ï¸âƒ£ ì˜ì—­ ì§€ì •")
    zoom = st.slider("ğŸ” ì´ë¯¸ì§€ í™•ëŒ€/ì¶•ì†Œ", 400, 1500, 700)
    display_img = raw.copy()
    display_img.thumbnail((zoom, zoom))
    
    # ğŸš€ [ë³µêµ¬] ì „ì²´ ì„ íƒ ë° Undo ë²„íŠ¼
    col_sel1, col_sel2, col_sel3 = st.columns([2, 1, 1])
    with col_sel1: st.info(f"ğŸ‘‡ **ëª¨ì„œë¦¬ 4ê³³ì„ í´ë¦­**í•˜ì„¸ìš”. ({len(st.session_state['points'])}/4)")
    with col_sel2:
        if st.button("â¹ï¸ ì´ë¯¸ì§€ ì „ì²´ ì„ íƒ", type="primary", use_container_width=True):
            w, h = display_img.size
            st.session_state['points'] = [(0, 0), (w, 0), (w, h), (0, h)]
            st.rerun()
    with col_sel3:
        if st.button("âŒ ì  ì§€ìš°ê¸° (Undo)", use_container_width=True):
            st.session_state['points'] = []; st.rerun()
    
    draw = ImageDraw.Draw(display_img)
    for i, p in enumerate(st.session_state['points']):
        draw.ellipse((p[0]-8, p[1]-8, p[0]+8, p[1]+8), fill='red', outline='white', width=2)
        draw.text((p[0]+12, p[1]-12), str(i+1), fill='red')

    val = streamlit_image_coordinates(display_img, key="roi_click")
    if val:
        new_p = (val['x'], val['y'])
        if len(st.session_state['points']) < 4:
            if not st.session_state['points'] or st.session_state['points'][-1] != new_p:
                st.session_state['points'].append(new_p); st.rerun()

    if len(st.session_state['points']) == 4:
        st.markdown("---")
        ratio = raw.width / display_img.width
        pts = np.array(st.session_state['points'], dtype="float32") * ratio
        warped = four_point_transform(np.array(raw), pts)
        final_crop = Image.fromarray(warped)
        
        if is_photo:
            final_crop = apply_smart_filters(final_crop, material_type, lighting, brightness, sharpness)
        
        col_res1, col_res2 = st.columns([1, 2])
        with col_res1: st.image(final_crop, caption="ìµœì¢… ë¶„ì„ ì´ë¯¸ì§€", width=350)
        with col_res2:
            st.write("âœ… ì˜ì—­ ì§€ì • ì™„ë£Œ. ìœ ì‚¬í•œ ìì¬ë¥¼ ê²€ìƒ‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ?")
            if st.button("ğŸ” ê²€ìƒ‰ ì‹œì‘", type="primary", use_container_width=True):
                with st.spinner('AI ë¶„ì„ ì¤‘...'):
                    proc_img = prepare_image_for_ai(final_crop, search_mode)
                    x = image.img_to_array(proc_img)
                    x = np.expand_dims(x, axis=0)
                    query_vec = model.predict(preprocess_input(x), verbose=0).flatten().reshape(1, -1)
                    
                    db_names, db_vecs = list(feature_db.keys()), np.array(list(feature_db.values()))
                    sims = cosine_similarity(query_vec, db_vecs).flatten()
                    
                    results = []
                    for i in range(len(db_names)):
                        digits = extract_digits(db_names[i])
                        info = master_map.get(digits, {'formal': db_names[i], 'name': 'ì •ë³´ ì—†ìŒ', 'lab_no': '-'})
                        url_match = df_path[df_path['ì¶”ì¶œëœ_í’ˆë²ˆ'].apply(extract_digits) == digits]
                        url = url_match.iloc[0]['ì¹´ì¹´ì˜¤í†¡_ì „ì†¡ìš©_URL'] if not url_match.empty else None
                        stock = agg_stock.get(extract_digits(info['formal']), 0)
                        
                        results.append({
                            'formal': info['formal'], 
                            'name': info['name'], 
                            'lab_no': info['lab_no'], 
                            'score': sims[i], 
                            'stock': stock, 
                            'url': url
                        })
                    
                    results.sort(key=lambda x: x['score'], reverse=True)
                    unique_res, seen = [], set()
                    for r in results:
                        if r['formal'] not in seen:
                            unique_res.append(r); seen.add(r['formal'])
                    
                    st.session_state['search_results'] = unique_res[:20]
                    st.session_state['search_done'] = True
                    st.rerun()

# -----------------------------------------------------------
# --- [4] ê²°ê³¼ ì¶œë ¥ (KeyError ë°©ì§€ ë° ì•ˆì •í™”) ---
# -----------------------------------------------------------

if st.session_state.get('search_done'):
    st.markdown("### ğŸ† ê²€ìƒ‰ ê²°ê³¼")
    results = st.session_state.get('search_results', [])
    
    def display_card(item, idx):
        title = f"{idx}. {item['formal']}"
        if item['lab_no'] != '-' and item['lab_no'] != item['formal']:
            title += f" (Lab: {item['lab_no']})"
        
        st.markdown(f"**{title}**")
        st.write(f"{item['name']}")
        st.caption(f"ìœ ì‚¬ë„: {item['score']:.1%}")
        
        if item['url']:
            with st.expander("ğŸ–¼ï¸ ì´ë¯¸ì§€ í™•ì¸"):
                try:
                    r = requests.get(get_direct_url(item['url']), timeout=5)
                    st.image(Image.open(BytesIO(r.content)), use_container_width=True)
                except: st.write("ë¡œë”© ì‹¤íŒ¨")
            st.markdown(f"ğŸ”— [ê³ í™”ì§ˆ ì›ë³¸]({item['url']})")
        else: st.write("ì´ë¯¸ì§€ ì—†ìŒ")
        
        if item['stock'] >= 100: st.success(f"{item['stock']:,}m")
        else: st.info(f"{item['stock']:,}m")

    t1, t2 = st.tabs(["ğŸ“Š ì „ì²´ ê²°ê³¼", "âœ… ì¬ê³  ë³´ìœ  (100mâ†‘)"])
    with t1:
        cols = st.columns(5)
        for i, r in enumerate(results[:10]):
            with cols[i % 5]: display_card(r, i+1)
    with t2:
        hits = [r for r in results if r['stock'] >= 100]
        if hits:
            cols = st.columns(5)
            for i, r in enumerate(hits[:10]):
                with cols[i % 5]: display_card(r, i+1)
        else: st.warning("ì¬ê³  ë³´ìœ  ìì¬ ì—†ìŒ")
