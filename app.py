import streamlit as st
import pandas as pd
import pickle
import numpy as np
import re
import os
from PIL import Image
from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input
from tensorflow.keras.preprocessing import image
from sklearn.metrics.pairwise import cosine_similarity

# --- [ë³´ì¡° í•¨ìˆ˜: í•œê¸€ ê¹¨ì§ ë° ëŒ€ì†Œë¬¸ì ë¬´ì‹œ ë¡œë“œ] ---
def load_csv_smart(target_name):
    """íŒŒì¼ ì´ë¦„ ëŒ€ì†Œë¬¸ì êµ¬ë¶„ ì—†ì´ ì°¾ê³ , í•œê¸€ ì¸ì½”ë”©(UTF-8, CP949)ì„ ìë™ í•´ê²°"""
    found_file = None
    for f in os.listdir('.'):
        if f.lower() == target_name.lower():
            found_file = f
            break
    
    if not found_file:
        st.error(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {target_name}")
        st.stop()
        
    for enc in ['utf-8', 'cp949', 'euc-kr']:
        try:
            return pd.read_csv(found_file, encoding=enc)
        except UnicodeDecodeError:
            continue
    st.error(f"âŒ {target_name}ì˜ ì¸ì½”ë”©ì„ íŒë³„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    st.stop()

# --- [1] ë¦¬ì†ŒìŠ¤ ë¡œë“œ (ìºì‹±) ---
@st.cache_resource
def init_resources():
    model = ResNet50(weights='imagenet', include_top=False, pooling='avg')
    with open('material_features.pkl', 'rb') as f:
        feature_db = pickle.load(f)
    
    df_path = load_csv_smart('ì´ë¯¸ì§€ê²½ë¡œ.csv')
    df_info = load_csv_smart('í’ˆëª©ì •ë³´.csv')
    df_stock = load_csv_smart('í˜„ì¬ê³ .csv')
    
    # ì¬ê³  ìˆ˜ëŸ‰ ì „ì²˜ë¦¬ ë° í’ˆë²ˆë³„ í•©ì‚°
    df_stock['ì¬ê³ ìˆ˜ëŸ‰'] = pd.to_numeric(df_stock['ì¬ê³ ìˆ˜ëŸ‰'].astype(str).str.replace(',', ''), errors='coerce').fillna(0)
    df_stock['í’ˆë²ˆ_KEY'] = df_stock['í’ˆë²ˆ'].astype(str).str.strip().str.upper()
    agg_stock = df_stock.groupby('í’ˆë²ˆ_KEY')['ì¬ê³ ìˆ˜ëŸ‰'].sum().to_dict()
    
    # ë‚ ì§œ ì¶”ì¶œ
    stock_date = "í™•ì¸ë¶ˆê°€"
    if 'ì •ì‚°ì¼ì' in df_stock.columns:
        d = str(int(df_stock['ì •ì‚°ì¼ì'].max()))
        stock_date = f"{d[:4]}-{d[4:6]}-{d[6:8]}"
        
    return model, feature_db, df_path, df_info, agg_stock, stock_date

model, feature_db, df_path, df_info, agg_stock, stock_date = init_resources()

# --- [2] ë§¤ì¹­ ë° ê²€ìƒ‰ í•¨ìˆ˜ ---
def get_only_digits(text):
    if not text or pd.isna(text): return ""
    return "".join(re.findall(r'\d+', str(text)))

@st.cache_data
def get_item_map():
    mapping = {}
    for _, row in df_info.iterrows():
        f_code = str(row['ìƒí’ˆì½”ë“œ']).strip()
        l_no = str(row['Lab No']).strip()
        p_name = str(row['ìƒí’ˆëª…']).strip()
        
        # ë©ë„˜ë²„ì™€ ì •ì‹í’ˆë²ˆ ìˆ«ìë¥¼ ëª¨ë‘ í‚¤ë¡œ ì‚¬ìš©
        k_lab = get_only_digits(l_no)
        k_formal = get_only_digits(f_code)
        
        val = {'formal': f_code, 'name': p_name}
        if k_lab: mapping[k_lab] = val
        if k_formal: mapping[k_formal] = val
    return mapping

master_map = get_item_map()

# --- [3] UI êµ¬ì„± ---
st.set_page_config(layout="wide", page_title="ìì¬ íŒ¨í„´ ë§¤ì¹­")
st.title("ğŸ­ ìì¬ íŒ¨í„´ ê²€ìƒ‰ ë° ì‹¤ì‹œê°„ ì¬ê³  í™•ì¸")
st.sidebar.info(f"ğŸ“… ì¬ê³  ê¸°ì¤€ì¼: {stock_date}")

uploaded = st.file_uploader("ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”", type=['jpg', 'jpeg', 'png', 'tif', 'tiff'])

if uploaded:
    # ì‚¬ìš©ì ì´ë¯¸ì§€ íŠ¹ì§• ì¶”ì¶œ
    target_img = Image.open(uploaded).convert('RGB').resize((224, 224))
    st.image(uploaded, width=250, caption="ì¡°íšŒ íŒ¨í„´")

    with st.spinner('íŒ¨í„´ ë¶„ì„ ë° ì¬ê³  ëŒ€ì¡° ì¤‘...'):
        x = image.img_to_array(target_img)
        x = np.expand_dims(x, axis=0)
        query_vec = model.predict(preprocess_input(x), verbose=0).flatten().reshape(1, -1)
        
        db_names = list(feature_db.keys())
        db_vecs = np.array(list(feature_db.values()))
        sims = cosine_similarity(query_vec, db_vecs).flatten()
        
        results = []
        for i in range(len(db_names)):
            fname = db_names[i]
            core = get_only_digits(fname)
            info = master_map.get(core, {'formal': fname, 'name': 'ì •ë³´ ì—†ìŒ'})
            
            # ì •ë°€ ì¬ê³  ë§¤ì¹­ (ëŒ€ì†Œë¬¸ì/ê³µë°± ì œê±° í›„ ì¼ì¹˜ í™•ì¸)
            formal_code = info['formal']
            stock_key = formal_code.strip().upper()
            qty = agg_stock.get(stock_key, 0)
            
            # ì´ë¯¸ì§€ URL
            url_row = df_path[df_path['íŒŒì¼ëª…'] == fname]
            url = url_row['ì¹´ì¹´ì˜¤í†¡_ì „ì†¡ìš©_URL'].values[0] if not url_row.empty else None
            
            results.append({
                'formal': formal_code, 'name': info['name'],
                'score': sims[i], 'stock': qty, 'url': url
            })
        
        results = sorted(results, key=lambda x: x['score'], reverse=True)

    # ê²°ê³¼ ì¶œë ¥
    t1, t2 = st.tabs(["ğŸ“Š ì „ì²´ ìœ ì‚¬ ê²°ê³¼", "âœ… ì¬ê³  ìˆìŒ (100mâ†‘)"])
    with t1:
        cols = st.columns(5)
        for i, r in enumerate(results[:10]):
            with cols[i%5]:
                st.image(r['url'] if r['url'] else "https://via.placeholder.com/150")
                st.markdown(f"**{r['formal']}**")
                st.caption(f"ìœ ì‚¬ë„: {r['score']:.1%}")
                st.write(f"ì¬ê³ : {r['stock']:,}m")
    with t2:
        in_stock = [r for r in results if r['stock'] >= 100]
        if in_stock:
            cols = st.columns(5)
            for i, r in enumerate(in_stock[:10]):
                with cols[i%5]:
                    st.image(r['url'] if r['url'] else "https://via.placeholder.com/150")
                    st.success(f"**{r['formal']}**")
                    st.write(f"í’ˆëª…: {r['name']}")
                    st.write(f"**ì‹¤ì¬ê³ : {r['stock']:,}m**")
        else:
            st.warning("ì¬ê³ ê°€ 100m ì´ìƒì¸ ìì¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
