import streamlit as st
import pandas as pd
import pickle
import numpy as np
import re
import os
import requests
import cv2
import base64
from PIL import Image, ImageEnhance, ImageDraw, ImageFilter
from io import BytesIO
from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input
from tensorflow.keras.preprocessing import image
from sklearn.metrics.pairwise import cosine_similarity
from streamlit_image_coordinates import streamlit_image_coordinates

# -----------------------------------------------------------
# ğŸš‘ [í•„ìˆ˜ íŒ¨ì¹˜] Streamlit í˜¸í™˜ì„± & í° í™”ë©´ í•´ê²°
# -----------------------------------------------------------
import streamlit.elements.image as st_image

def local_image_to_url(image, width=None, clamp=False, channels="RGB", output_format="auto", image_id=None):
    buffered = BytesIO()
    image.save(buffered, format="PNG")
    img_str = base64.b64encode(buffered.getvalue()).decode()
    return f"data:image/png;base64,{img_str}"

if not hasattr(st_image, 'image_to_url'):
    st_image.image_to_url = local_image_to_url

# -----------------------------------------------------------
# --- [1] ìœ í‹¸ë¦¬í‹° ë° ë¦¬ì†ŒìŠ¤ ---
# -----------------------------------------------------------

def get_direct_url(url):
    """êµ¬ê¸€ ë“œë¼ì´ë¸Œ ë§í¬ë¥¼ ì§ì ‘ ë‹¤ìš´ë¡œë“œ ê°€ëŠ¥í•œ URLë¡œ ë³€í™˜"""
    if not url or str(url) == 'nan' or 'drive.google.com' not in url: 
        return url
    
    file_id = ""
    if 'file/d/' in url:
        file_id = url.split('file/d/')[1].split('/')[0]
    elif 'id=' in url:
        file_id = url.split('id=')[1].split('&')[0]
    
    if file_id:
        return f'https://drive.google.com/uc?export=download&id={file_id}'
    return url

def load_csv_smart(target_name):
    files = os.listdir('.')
    for f in files:
        if f.lower() == target_name.lower():
            for enc in ['utf-8-sig', 'utf-8', 'cp949', 'euc-kr']:
                try: return pd.read_csv(f, encoding=enc)
                except: continue
    st.error(f"âŒ {target_name} íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    st.stop()

def extract_digits(text):
    if pd.isna(text) or str(text).strip() == '-': return ""
    text = str(text)
    # 4ìë¦¬ ì´ìƒì˜ ìˆ«ì ë­‰ì¹˜ë¥¼ ì¶”ì¶œ (Lab No ë° í’ˆë²ˆ í•µì‹¬ ìˆ«ì)
    nums = re.findall(r'\d{4,}', text)
    return nums[0] if nums else ""

def is_formal_code(code):
    """ì •ì‹ í’ˆë²ˆ í˜•ì‹(ì˜ˆ: 14-54130-119)ì¸ì§€ í™•ì¸í•˜ëŠ” ë¡œì§"""
    if not code or pd.isna(code): return False
    # í•˜ì´í”ˆì´ ë‘ ê°œ í¬í•¨ëœ ìˆ«ì ìœ„ì£¼ì˜ í˜•ì‹ì„ ì •ì‹ìœ¼ë¡œ íŒë‹¨
    pattern = r'^\d+-\d+-\d+$'
    return bool(re.match(pattern, str(code).strip()))

@st.cache_resource
def init_resources():
    model = ResNet50(weights='imagenet', include_top=False, pooling='avg')
    
    # íŠ¹ì§•ê°’ DB ë¡œë“œ
    if os.path.exists('material_features.pkl'):
        with open('material_features.pkl', 'rb') as f:
            feature_db = pickle.load(f)
    else:
        st.error("âŒ material_features.pkl íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        st.stop()

    df_path = load_csv_smart('ì´ë¯¸ì§€ê²½ë¡œ.csv')
    df_info = load_csv_smart('í’ˆëª©ì •ë³´.csv')
    df_stock = load_csv_smart('í˜„ì¬ê³ .csv')
    
    df_stock['ì¬ê³ ìˆ˜ëŸ‰'] = pd.to_numeric(df_stock['ì¬ê³ ìˆ˜ëŸ‰'].astype(str).str.replace(',', ''), errors='coerce').fillna(0)
    df_stock['í’ˆë²ˆ_KEY'] = df_stock['í’ˆë²ˆ'].apply(extract_digits)
    df_stock.loc[df_stock['í’ˆë²ˆ_KEY'] == "", 'í’ˆë²ˆ_KEY'] = df_stock['í’ˆë²ˆ'].astype(str).str.strip().str.upper()
    
    agg_stock = df_stock.groupby('í’ˆë²ˆ_KEY')['ì¬ê³ ìˆ˜ëŸ‰'].sum().to_dict()
    stock_date = str(int(df_stock['ì •ì‚°ì¼ì'].max())) if 'ì •ì‚°ì¼ì' in df_stock.columns else "í™•ì¸ë¶ˆê°€"
    
    return model, feature_db, df_path, df_info, agg_stock, stock_date

model, feature_db, df_path, df_info, agg_stock, stock_date = init_resources()

@st.cache_data
def get_master_map():
    mapping = {}
    for _, row in df_info.iterrows():
        f = str(row['ìƒí’ˆì½”ë“œ']).strip() if pd.notna(row.get('ìƒí’ˆì½”ë“œ')) else ''
        l = str(row.get('Lab No', '')).strip() if pd.notna(row.get('Lab No')) else ''
        n = str(row.get('ìƒí’ˆëª…', '')).strip() if pd.notna(row.get('ìƒí’ˆëª…')) else ''
        
        # ê¸°ë³¸ ì •ë³´ ê°ì²´
        current_formal = f if f else l
        info = {'formal': current_formal, 'name': n, 'lab_no': l}
        
        # ë§¤í•‘í•  í‚¤ í›„ë³´ë“¤ (ìˆ«ì ë° ì „ì²´ ì½”ë“œ)
        keys = set()
        f_digits = extract_digits(f)
        if f_digits: keys.add(f_digits)
        l_digits = extract_digits(l)
        if l_digits: keys.add(l_digits)
        if f: keys.add(f)
        if l: keys.add(l)
        
        for k in keys:
            if k not in mapping:
                mapping[k] = info
            else:
                # ğŸš€ [í•µì‹¬] ê¸°ì¡´ì— ë“±ë¡ëœ ë²ˆí˜¸ì™€ ë¹„êµí•˜ì—¬ ì •ì‹ ê·œê²©(14-54130-119 ë“±)ì„ ìš°ì„ ìˆœìœ„ë¡œ ë‘ 
                existing_formal = mapping[k]['formal']
                if is_formal_code(current_formal) and not is_formal_code(existing_formal):
                    mapping[k] = info
    return mapping

master_map = get_master_map()

# -----------------------------------------------------------
# --- [2] ì´ë¯¸ì§€ ì²˜ë¦¬ í•¨ìˆ˜ë“¤ ---
# -----------------------------------------------------------

def order_points(pts):
    rect = np.zeros((4, 2), dtype="float32")
    s = pts.sum(axis=1)
    rect[0] = pts[np.argmin(s)] 
    rect[2] = pts[np.argmax(s)] 
    diff = np.diff(pts, axis=1)
    rect[1] = pts[np.argmin(diff)] 
    rect[3] = pts[np.argmax(diff)] 
    return rect

def four_point_transform(image, pts):
    rect = order_points(pts)
    (tl, tr, br, bl) = rect
    widthA = np.sqrt(((br[0] - bl[0]) ** 2) + ((br[1] - bl[1]) ** 2))
    widthB = np.sqrt(((tr[0] - tl[0]) ** 2) + ((tr[1] - tl[1]) ** 2))
    maxWidth = max(int(widthA), int(widthB))
    heightA = np.sqrt(((tr[0] - br[0]) ** 2) + ((tr[1] - br[1]) ** 2))
    heightB = np.sqrt(((tl[0] - bl[0]) ** 2) + ((tl[1] - bl[1]) ** 2))
    maxHeight = max(int(heightA), int(heightB))
    dst = np.array([[0, 0], [maxWidth - 1, 0], [maxWidth - 1, maxHeight - 1], [0, maxHeight - 1]], dtype="float32")
    M = cv2.getPerspectiveTransform(rect, dst)
    warped = cv2.warpPerspective(image, M, (maxWidth, maxHeight))
    return warped

def apply_smart_filters(img, category, lighting, brightness, sharpness):
    if lighting == 'ë°±ì—´ë“± (ëˆ„ëŸ° ì¡°ëª…)':
        r, g, b = img.split()
        b = b.point(lambda i: i * 1.2)
        img = Image.merge('RGB', (r, g, b))
    elif lighting == 'í˜•ê´‘ë“± (í‘¸ë¥¸/ë…¹ìƒ‰ ì¡°ëª…)':
        r, g, b = img.split()
        r = r.point(lambda i: i * 1.1)
        img = Image.merge('RGB', (r, g, b))

    enhancer_con = ImageEnhance.Contrast(img)
    enhancer_shp = ImageEnhance.Sharpness(img)
    enhancer_bri = ImageEnhance.Brightness(img)
    enhancer_col = ImageEnhance.Color(img)

    if category == 'ë§ˆë£¨/ìš°ë“œ (Wood)':
        img = enhancer_shp.enhance(2.0)
        img = enhancer_con.enhance(1.1)
    elif category == 'í•˜ì´ê·¸ë¡œì‹œ/ìœ ê´‘ (Glossy)':
        img = enhancer_con.enhance(1.5)
        img = enhancer_shp.enhance(1.2)
    elif category == 'ë²½ì§€/íŒ¨ë¸Œë¦­ (Texture)':
        img = enhancer_shp.enhance(1.5)
        img = enhancer_bri.enhance(1.1)
    elif category == 'ì„ì¬/ì½˜í¬ë¦¬íŠ¸ (Stone)':
        img = enhancer_col.enhance(0.8)
        img = enhancer_shp.enhance(1.5)
    
    if brightness != 1.0: img = enhancer_bri.enhance(brightness)
    if sharpness != 1.0: img = enhancer_shp.enhance(sharpness)
        
    return img

def resize_for_display(img, max_width=800):
    if img.width > max_width:
        w_percent = (max_width / float(img.width))
        h_size = int((float(img.height) * float(w_percent)))
        return img.resize((max_width, h_size), Image.Resampling.LANCZOS)
    return img

# -----------------------------------------------------------
# --- [3] ë©”ì¸ UI ë ˆì´ì•„ì›ƒ ---
# -----------------------------------------------------------

st.set_page_config(layout="wide", page_title="ìŠ¤ë§ˆíŠ¸ ìì¬ ê²€ìƒ‰")
st.title("ğŸ­ ìŠ¤ë§ˆíŠ¸ ìì¬ íŒ¨í„´ ê²€ìƒ‰")
st.sidebar.info(f"ğŸ“… ì¬ê³  ê¸°ì¤€ì¼: {stock_date}")

if 'points' not in st.session_state: st.session_state['points'] = []
if 'uploader_key' not in st.session_state: st.session_state['uploader_key'] = 0
if 'search_done' not in st.session_state: st.session_state['search_done'] = False

tab1, tab2 = st.tabs(["ğŸ“‚ íŒŒì¼ ì—…ë¡œë“œ", "ğŸ“¸ ì¹´ë©”ë¼ ì´¬ì˜"])

input_file = None
active_source = None

with tab1:
    uploaded = st.file_uploader("ì´ë¯¸ì§€ íŒŒì¼ ì„ íƒ", type=['jpg', 'png', 'tif', 'jpeg'], key=f"up_{st.session_state['uploader_key']}")
    if uploaded:
        input_file = uploaded
        active_source = "upload"

with tab2:
    camera_shot = st.camera_input("ì¹´ë©”ë¼ë¡œ ì°ê¸°")
    if camera_shot:
        input_file = camera_shot
        active_source = "camera"

if st.sidebar.button("ğŸ”„ ì²˜ìŒë¶€í„° ë‹¤ì‹œ í•˜ê¸° (Reset)"):
    st.session_state['points'] = []
    st.session_state['search_done'] = False
    st.session_state['search_results'] = None
    st.session_state['uploader_key'] += 1
    st.session_state['proc_img'] = None
    st.session_state['current_img_name'] = None
    st.rerun()

if input_file:
    is_new = False
    file_id = input_file.name if hasattr(input_file, 'name') else "camera_img"
    
    if 'current_img_name' not in st.session_state or st.session_state['current_img_name'] != file_id:
        is_new = True

    if is_new:
        st.session_state['points'] = []
        st.session_state['search_done'] = False
        st.session_state['search_results'] = None
        st.session_state['current_img_name'] = file_id
        
        with st.spinner('ğŸ“¸ ì´ë¯¸ì§€ ìµœì í™” ì¤‘...'):
            raw = Image.open(input_file).convert('RGB')
            st.session_state['raw_img'] = raw
            st.session_state['proc_img'] = resize_for_display(raw, max_width=800)
        st.rerun()

    if 'raw_img' in st.session_state:
        working_raw = st.session_state['raw_img']

        st.markdown("### 1ï¸âƒ£ í™˜ê²½ ì„¤ì •")
        source_type = st.radio("ğŸ“‚ ì›ë³¸ ì¢…ë¥˜", ['ğŸ“¸ í˜„ì¥ ì´¬ì˜ ì‚¬ì§„', 'ğŸ’» ì´ë¯¸ì§€ íŒŒì¼ (ìŠ¤ìº”/ë””ì§€í„¸)'], index=0, horizontal=True)
        is_photo = (source_type == 'ğŸ“¸ í˜„ì¥ ì´¬ì˜ ì‚¬ì§„')

        col_opt1, col_opt2 = st.columns(2)
        with col_opt1:
            material_type = st.selectbox("ğŸ§± ìì¬ ì¢…ë¥˜", ['ì¼ë°˜ (ê¸°ë³¸)', 'ë§ˆë£¨/ìš°ë“œ (Wood)', 'í•˜ì´ê·¸ë¡œì‹œ/ìœ ê´‘ (Glossy)', 'ë²½ì§€/íŒ¨ë¸Œë¦­ (Texture)', 'ì„ì¬/ì½˜í¬ë¦¬íŠ¸ (Stone)'], disabled=not is_photo)
        with col_opt2:
            search_mode = st.radio("ğŸ” ê²€ìƒ‰ ê¸°ì¤€", ["ğŸ¨ ì»¬ëŸ¬ + íŒ¨í„´ (ê¸°ë³¸)", "ğŸ¦“ íŒ¨í„´/ì§ˆê° ì¤‘ì‹¬ (í‘ë°±)", "ğŸ¨ ì»¬ëŸ¬/í†¤ ì¤‘ì‹¬ (íŒ¨í„´ ë­‰ê°œê¸°)"], horizontal=True)

        st.markdown("### 2ï¸âƒ£ ì˜ì—­ ì§€ì •")
        zoom_level = st.slider("ğŸ” ì´ë¯¸ì§€ í™•ëŒ€/ì¶•ì†Œ", 300, 1500, 600, 50)
        display_img = resize_for_display(working_raw, max_width=zoom_level)

        col_sel1, col_sel2 = st.columns([3, 2])
        with col_sel1: st.info(f"ğŸ‘‡ **ëª¨ì„œë¦¬ 4ê³³ì„ í´ë¦­**í•˜ì„¸ìš”. ({len(st.session_state['points'])}/4)")
        with col_sel2:
            if st.button("â¹ï¸ ì „ì²´ ì„ íƒ (ìŠ¤ìº”íŒŒì¼ìš©)", type="primary"):
                w, h = display_img.size
                st.session_state['points'] = [(0, 0), (w, 0), (w, h), (0, h)]
                st.rerun()

        draw_img = display_img.copy()
        draw = ImageDraw.Draw(draw_img)
        for i, p in enumerate(st.session_state['points']):
            draw.ellipse((p[0]-8, p[1]-8, p[0]+8, p[1]+8), fill='red', outline='white', width=2)
            draw.text((p[0]+10, p[1]-10), str(i+1), fill='red')

        if len(st.session_state['points']) == 4:
            pts = np.array(st.session_state['points'])
            rect = order_points(pts)
            draw.polygon([tuple(p) for p in rect], outline='#00FF00', width=4)

        value = streamlit_image_coordinates(draw_img, key=f"click_pad_{zoom_level}")

        if value is not None:
            new_point = (value['x'], value['y'])
            if len(st.session_state['points']) < 4:
                if not st.session_state['points'] or st.session_state['points'][-1] != new_point:
                    st.session_state['points'].append(new_point)
                    st.rerun()

        if len(st.session_state['points']) == 4:
            st.markdown("### 3ï¸âƒ£ ë¶„ì„ ê²°ê³¼")
            ratio = working_raw.width / display_img.width
            original_pts = np.array(st.session_state['points'], dtype="float32") * ratio
            
            cv_img = np.array(working_raw)
            warped = four_point_transform(cv_img, original_pts)
            final_img = Image.fromarray(warped)
            
            if is_photo:
                final_img = apply_smart_filters(final_img, material_type, 'ì¼ë°˜/ìì—°ê´‘', 1.0, 1.5)
            
            proc_img_for_ai = final_img.copy()
            if search_mode == "ğŸ¦“ íŒ¨í„´/ì§ˆê° ì¤‘ì‹¬ (í‘ë°±)": proc_img_for_ai = final_img.convert("L").convert("RGB")
            elif search_mode == "ğŸ¨ ì»¬ëŸ¬/í†¤ ì¤‘ì‹¬ (íŒ¨í„´ ë­‰ê°œê¸°)": proc_img_for_ai = final_img.filter(ImageFilter.GaussianBlur(radius=10))

            st.image(final_img, caption="ë¶„ì„ ëŒ€ìƒ ì´ë¯¸ì§€", width=300)
            
            if st.button("ğŸ” ìœ ì‚¬ ìì¬ ê²€ìƒ‰ ì‹œì‘", type="primary"):
                with st.spinner('ìœ ì‚¬í•œ ìì¬ ì°¾ëŠ” ì¤‘...'):
                    x = image.img_to_array(proc_img_for_ai.resize((224, 224)))
                    x = np.expand_dims(x, axis=0)
                    query_vec = model.predict(preprocess_input(x), verbose=0).flatten().reshape(1, -1)
                    
                    db_names, db_vecs = list(feature_db.keys()), np.array(list(feature_db.values()))
                    sims = cosine_similarity(query_vec, db_vecs).flatten()
                    
                    raw_results = []
                    for i in range(len(db_names)):
                        fname = db_names[i]
                        target_digits = extract_digits(fname)
                        info = master_map.get(target_digits)
                        
                        if not info:
                            info = {'formal': fname, 'name': 'ì •ë³´ ì—†ìŒ', 'lab_no': '-'}

                        qty = agg_stock.get(extract_digits(info['formal']), 0)
                        
                        url_match = df_path[df_path['ì¶”ì¶œëœ_í’ˆë²ˆ'].apply(extract_digits) == target_digits]
                        url = url_match.iloc[0]['ì¹´ì¹´ì˜¤í†¡_ì „ì†¡ìš©_URL'] if not url_match.empty else None
                        
                        raw_results.append({'formal': info['formal'], 'name': info['name'], 'lab_no': info['lab_no'], 'score': sims[i], 'stock': qty, 'url': url})
                    
                    raw_results.sort(key=lambda x: x['score'], reverse=True)
                    
                    seen_codes, unique_results = set(), []
                    for res in raw_results:
                        if res['formal'] not in seen_codes:
                            unique_results.append(res)
                            seen_codes.add(res['formal'])
                    
                    st.session_state['search_results'] = unique_results
                    st.session_state['search_done'] = True
                    st.rerun()

# -----------------------------------------------------------
# --- [4] ê²°ê³¼ í‘œì‹œ (ì´ë¯¸ì§€ ë§í¬ ìˆ˜ì • ë°˜ì˜) ---
# -----------------------------------------------------------

if st.session_state.get('search_done'):
    st.markdown("---")
    results = st.session_state['search_results']

    def display_card(item, idx):
        title_text = f"{idx}. {item['formal']}"
        if item['lab_no'] != '-' and item['lab_no'] != item['formal']:
            title_text += f" (Lab: {item['lab_no']})"
        st.markdown(f"**{title_text}**")
        st.write(f"{item['name']}")
        st.caption(f"ìœ ì‚¬ë„: {item['score']:.1%}")
        
        if item['url']:
            direct_url = get_direct_url(item['url'])
            st.markdown(f"ğŸ”— [**ê³ í™”ì§ˆ ì›ë³¸**]({item['url']})")
            with st.expander("ğŸ–¼ï¸ ì´ë¯¸ì§€ ë³´ê¸°", expanded=False):
                try:
                    # êµ¬ê¸€ ë“œë¼ì´ë¸Œ ë³´ì•ˆ ì´ìŠˆë¡œ ì¸í•´ requestsë¡œ ë°ì´í„°ë¥¼ ë°›ì•„ì™€ì„œ í‘œì‹œ
                    resp = requests.get(direct_url, timeout=5)
                    st.image(Image.open(BytesIO(resp.content)), use_container_width=True)
                except:
                    st.warning("ì´ë¯¸ì§€ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ìœ„ ë§í¬ë¥¼ í´ë¦­í•˜ì„¸ìš”.")
        else:
            st.write("ì´ë¯¸ì§€ ì—†ìŒ")
        
        stock_text = f"{item['stock']:,}m"
        if item['stock'] >= 100: st.success(stock_text)
        else: st.write(stock_text)

    t1, t2 = st.tabs(["ğŸ“Š ì „ì²´ ê²°ê³¼", "âœ… ì¬ê³  ë³´ìœ  (100mâ†‘)"])
    with t1:
        cols = st.columns(5)
        for i, r in enumerate(results[:10]):
            with cols[i%5]: display_card(r, i+1)
    with t2:
        hits = [r for r in results if r['stock'] >= 100]
        if hits:
            cols = st.columns(5)
            for i, r in enumerate(hits[:10]):
                with cols[i%5]: display_card(r, i+1)
        else: st.warning("ì¬ê³  ë³´ìœ  ìì¬ ì—†ìŒ")
